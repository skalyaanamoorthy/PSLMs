{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, append Rosetta predictions to inference files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s461\n",
      "461 461\n",
      "ssym\n",
      "684 684\n",
      "korpm\n",
      "2369 2369\n",
      "korpm_full\n",
      "3822 3822\n",
      "Could not find predictions for 1ACB_11I\n",
      "Could not find predictions for 1AJ3_62A\n",
      "Could not find predictions for 1AJ3_62G\n",
      "Could not find predictions for 1AJ3_76G\n",
      "Could not find predictions for 1AXB_263F\n",
      "Could not find predictions for 1AYI_16A\n",
      "Could not find predictions for 1AYI_22V\n",
      "Could not find predictions for 1AYI_34A\n",
      "Could not find predictions for 1AYI_38A\n",
      "Could not find predictions for 1BK7_101A\n",
      "Could not find predictions for 1BK7_102A\n",
      "Could not find predictions for 1BK7_105L\n",
      "Could not find predictions for 1BK7_107A\n",
      "Could not find predictions for 1BK7_125A\n",
      "Could not find predictions for 1BK7_127A\n",
      "Could not find predictions for 1BK7_166A\n",
      "Could not find predictions for 1BK7_173A\n",
      "Could not find predictions for 1BK7_190A\n",
      "Could not find predictions for 1BNI_39A\n",
      "Could not find predictions for 1BNZ_12A\n",
      "Could not find predictions for 1BNZ_15A\n",
      "Could not find predictions for 1BNZ_18A\n",
      "Could not find predictions for 1BNZ_23A\n",
      "Could not find predictions for 1BNZ_25A\n",
      "Could not find predictions for 1BNZ_27A\n",
      "Could not find predictions for 1BNZ_30A\n",
      "Could not find predictions for 1BNZ_35A\n",
      "Could not find predictions for 1BNZ_37A\n",
      "Could not find predictions for 1BNZ_41A\n",
      "Could not find predictions for 1BNZ_46A\n",
      "Could not find predictions for 1BNZ_4A\n",
      "Could not find predictions for 1BNZ_51G\n",
      "Could not find predictions for 1BNZ_56A\n",
      "Could not find predictions for 1BNZ_59A\n",
      "Could not find predictions for 1BNZ_7A\n",
      "Could not find predictions for 1BU4_29A\n",
      "Could not find predictions for 1BU4_9A\n",
      "Could not find predictions for 1BVC_133A\n",
      "Could not find predictions for 1BVC_139A\n",
      "Could not find predictions for 1BVC_147A\n",
      "Could not find predictions for 1BVC_20A\n",
      "Could not find predictions for 1C9O_66L\n",
      "Could not find predictions for 1CFD_41A\n",
      "Could not find predictions for 1CM2_49A\n",
      "Could not find predictions for 1DKT_20A\n",
      "Could not find predictions for 1EGL_14A\n",
      "Could not find predictions for 1FKJ_6A\n",
      "Could not find predictions for 1FTG_104A\n",
      "Could not find predictions for 1FTG_106G\n",
      "Could not find predictions for 1FTG_108A\n",
      "Could not find predictions for 1FTG_7F\n",
      "Could not find predictions for 1FTG_84F\n",
      "Could not find predictions for 1FTG_91A\n",
      "Could not find predictions for 1FTG_99N\n",
      "Could not find predictions for 1G3P_76I\n",
      "Could not find predictions for 1G6P_40A\n",
      "Could not find predictions for 1G6P_62A\n",
      "Could not find predictions for 1GLM_136A\n",
      "Could not find predictions for 1GLM_250A\n",
      "Could not find predictions for 1GLM_382A\n",
      "Could not find predictions for 1H7M_48M\n",
      "Could not find predictions for 1HFY_27A\n",
      "Could not find predictions for 1JNX_124S\n",
      "Could not find predictions for 1JNX_129N\n",
      "Could not find predictions for 1JNX_157A\n",
      "Could not find predictions for 1JNX_159A\n",
      "Could not find predictions for 1JNX_44N\n",
      "Could not find predictions for 1JNX_57A\n",
      "Could not find predictions for 1JNX_87A\n",
      "Could not find predictions for 1K5U_17A\n",
      "Could not find predictions for 1K5U_19A\n",
      "Could not find predictions for 1K5U_59A\n",
      "Could not find predictions for 1K5U_61A\n",
      "Could not find predictions for 1K85_20A\n",
      "Could not find predictions for 1K85_22A\n",
      "Could not find predictions for 1K85_33A\n",
      "Could not find predictions for 1K85_36F\n",
      "Could not find predictions for 1K85_38A\n",
      "Could not find predictions for 1K85_44A\n",
      "Could not find predictions for 1K85_48A\n",
      "Could not find predictions for 1K85_55A\n",
      "Could not find predictions for 1K85_58A\n",
      "Could not find predictions for 1K85_64F\n",
      "Could not find predictions for 1K85_66L\n",
      "Could not find predictions for 1K85_68A\n",
      "Could not find predictions for 1K85_70G\n",
      "Could not find predictions for 1K85_81A\n",
      "Could not find predictions for 1K85_84A\n",
      "Could not find predictions for 1K85_86A\n",
      "Could not find predictions for 1OIA_51A\n",
      "Could not find predictions for 1QQV_52G\n",
      "Could not find predictions for 1RGG_11A\n",
      "Could not find predictions for 1RGG_19A\n",
      "Could not find predictions for 1RGG_21A\n",
      "Could not find predictions for 1RGG_22V\n",
      "Could not find predictions for 1RGG_24A\n",
      "Could not find predictions for 1RGG_31A\n",
      "Could not find predictions for 1RGG_3A\n",
      "Could not find predictions for 1RGG_42A\n",
      "Could not find predictions for 1RGG_70V\n",
      "Could not find predictions for 1RGG_71V\n",
      "Could not find predictions for 1RGG_8A\n",
      "Could not find predictions for 1RGG_90A\n",
      "Could not find predictions for 1RGG_91A\n",
      "Could not find predictions for 1RGG_92V\n",
      "Could not find predictions for 1RGG_95A\n",
      "Could not find predictions for 1RGG_9A\n",
      "Could not find predictions for 1RTB_83A\n",
      "Could not find predictions for 1RX4_136A\n",
      "Could not find predictions for 1RX4_156A\n",
      "Could not find predictions for 1RX4_4A\n",
      "Could not find predictions for 1RX4_61A\n",
      "Could not find predictions for 1RX4_8A\n",
      "Could not find predictions for 1RX4_91A\n",
      "Could not find predictions for 1U4Q_102G\n",
      "Could not find predictions for 1U4Q_104A\n",
      "Could not find predictions for 1U4Q_107A\n",
      "Could not find predictions for 1U4Q_110A\n",
      "Could not find predictions for 1U4Q_12G\n",
      "Could not find predictions for 1U4Q_14A\n",
      "Could not find predictions for 1U4Q_18A\n",
      "Could not find predictions for 1U4Q_20A\n",
      "Could not find predictions for 1U4Q_21A\n",
      "Could not find predictions for 1U4Q_22A\n",
      "Could not find predictions for 1U4Q_25A\n",
      "Could not find predictions for 1U4Q_35G\n",
      "Could not find predictions for 1U4Q_37A\n",
      "Could not find predictions for 1U4Q_40A\n",
      "Could not find predictions for 1U4Q_42A\n",
      "Could not find predictions for 1U4Q_46A\n",
      "Could not find predictions for 1U4Q_47A\n",
      "Could not find predictions for 1U4Q_49G\n",
      "Could not find predictions for 1U4Q_51A\n",
      "Could not find predictions for 1U4Q_54A\n",
      "Could not find predictions for 1U4Q_56A\n",
      "Could not find predictions for 1U4Q_58A\n",
      "Could not find predictions for 1U4Q_59A\n",
      "Could not find predictions for 1U4Q_5A\n",
      "Could not find predictions for 1U4Q_61A\n",
      "Could not find predictions for 1U4Q_65G\n",
      "Could not find predictions for 1U4Q_67A\n",
      "Could not find predictions for 1U4Q_67G\n",
      "Could not find predictions for 1U4Q_77A\n",
      "Could not find predictions for 1U4Q_79A\n",
      "Could not find predictions for 1U4Q_81A\n",
      "Could not find predictions for 1U4Q_83A\n",
      "Could not find predictions for 1U4Q_84A\n",
      "Could not find predictions for 1U4Q_86A\n",
      "Could not find predictions for 1U4Q_90A\n",
      "Could not find predictions for 1U4Q_91G\n",
      "Could not find predictions for 1U4Q_93A\n",
      "Could not find predictions for 1U4Q_97G\n",
      "Could not find predictions for 1U4Q_99G\n",
      "Could not find predictions for 1VII_11A\n",
      "Could not find predictions for 1VII_18A\n",
      "Could not find predictions for 1VII_21A\n",
      "Could not find predictions for 1VII_29A\n",
      "Could not find predictions for 1VII_35A\n",
      "Could not find predictions for 1VII_7A\n",
      "Could not find predictions for 1W4H_10V\n",
      "Could not find predictions for 1W4H_14A\n",
      "Could not find predictions for 1W4H_27S\n",
      "Could not find predictions for 1W4H_33A\n",
      "Could not find predictions for 1W4H_37N\n",
      "Could not find predictions for 1W4H_38A\n",
      "Could not find predictions for 1W4H_43G\n",
      "Could not find predictions for 1W4H_5G\n",
      "Could not find predictions for 1WQ5_234A\n",
      "Could not find predictions for 1WQ5_87A\n",
      "Could not find predictions for 1WQ5_92A\n",
      "Could not find predictions for 1WQ5_94A\n",
      "Could not find predictions for 1WY3_13V\n",
      "Could not find predictions for 1WY3_2A\n",
      "Could not find predictions for 1XYX_76K\n",
      "Could not find predictions for 1YGW_91A\n",
      "Could not find predictions for 1YGW_91V\n",
      "Could not find predictions for 1YGW_93A\n",
      "Could not find predictions for 1YGW_93V\n",
      "Could not find predictions for 1YRI_17A\n",
      "Could not find predictions for 1YRI_9A\n",
      "Could not find predictions for 2CK2_20A\n",
      "Could not find predictions for 2CK2_20V\n",
      "Could not find predictions for 2CK2_25A\n",
      "Could not find predictions for 2CK2_36A\n",
      "Could not find predictions for 2CK2_36F\n",
      "Could not find predictions for 2CK2_38A\n",
      "Could not find predictions for 2CK2_59A\n",
      "Could not find predictions for 2CK2_5A\n",
      "Could not find predictions for 2CK2_62A\n",
      "Could not find predictions for 2CK2_68F\n",
      "Could not find predictions for 2JOF_14A\n",
      "Could not find predictions for 2JOF_17A\n",
      "Could not find predictions for 2JOF_18A\n",
      "Could not find predictions for 2JOF_19A\n",
      "Could not find predictions for 2LCP_30F\n",
      "Could not find predictions for 2LSB_89N\n",
      "Could not find predictions for 2MMX_2L\n",
      "Could not find predictions for 2MMX_2W\n",
      "Could not find predictions for 2N53_45A\n",
      "Could not find predictions for 2RLK_13A\n",
      "Could not find predictions for 2RLK_14A\n",
      "Could not find predictions for 2RLK_21A\n",
      "Could not find predictions for 2RLK_27A\n",
      "Could not find predictions for 2RN4_10A\n",
      "Could not find predictions for 2SPZ_29G\n",
      "Could not find predictions for 2WZB_240A\n",
      "Could not find predictions for 3F6R_108A\n",
      "Could not find predictions for 3F6R_119A\n",
      "Could not find predictions for 3F6R_123A\n",
      "Could not find predictions for 3F6R_136A\n",
      "Could not find predictions for 3F6R_18G\n",
      "Could not find predictions for 3F6R_32A\n",
      "Could not find predictions for 3F6R_35A\n",
      "Could not find predictions for 3F6R_4A\n",
      "Could not find predictions for 3F6R_52A\n",
      "Could not find predictions for 3F6R_54A\n",
      "Could not find predictions for 3F6R_6A\n",
      "Could not find predictions for 3F6R_73A\n",
      "Could not find predictions for 3F6R_87A\n",
      "Could not find predictions for 3FFN_165N\n",
      "Could not find predictions for 5TR5_44A\n",
      "Could not find predictions for 9RNT_61V\n",
      "Could not find predictions for 9RNT_86A\n",
      "Could not find predictions for 9RNT_90V\n",
      "q3421\n",
      "3421 3421\n",
      "fireprot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2482202/1188725329.py:26: DtypeWarning: Columns (42) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  db2 = pd.read_csv(file1.replace('_preds', '').replace('inference', 'preprocessed'), index_col=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6455 53430\n",
      "Could not find predictions for 1AJ3_-1000000A\n",
      "Could not find predictions for 1AJ3_-1000000E\n",
      "Could not find predictions for 1AJ3_-1000000F\n",
      "Could not find predictions for 1AJ3_-1000000G\n",
      "Could not find predictions for 1AJ3_-1000000K\n",
      "Could not find predictions for 1AJ3_-1000000L\n",
      "Could not find predictions for 1AJ3_-1000000V\n",
      "Could not find predictions for 1AJ3_-1000000Y\n",
      "Could not find predictions for 1DPM_257L\n",
      "Could not find predictions for 1E21_-1000000A\n",
      "Could not find predictions for 1HYN_-1000000K\n",
      "Could not find predictions for 1PGA_-1000000F\n",
      "Could not find predictions for 1PGA_-1000000I\n",
      "Could not find predictions for 1PGA_-1000000V\n",
      "Could not find predictions for 1PGA_-1000000Y\n",
      "Could not find predictions for 1PIN_-1000000A\n",
      "Could not find predictions for 1PIN_-1000000G\n",
      "Could not find predictions for 1QLP_-1000000I\n",
      "Could not find predictions for 1QLP_-1000000L\n",
      "Could not find predictions for 1QLP_-1000000P\n",
      "Could not find predictions for 1QLP_-1000000V\n",
      "Could not find predictions for 1STN_-1000000A\n",
      "Could not find predictions for 1STN_-1000000F\n",
      "Could not find predictions for 1STN_-1000000G\n",
      "Could not find predictions for 1STN_-1000000K\n",
      "Could not find predictions for 1STN_-1000000N\n",
      "Could not find predictions for 1STN_-1000000V\n",
      "Could not find predictions for 1TTG_-1000000P\n",
      "Could not find predictions for 1TUP_-1000000A\n",
      "Could not find predictions for 1TUP_-1000000F\n",
      "Could not find predictions for 1TUP_-1000000G\n",
      "Could not find predictions for 1TUP_-1000000I\n",
      "Could not find predictions for 1TUP_-1000000L\n",
      "Could not find predictions for 1TUP_-1000000V\n",
      "Could not find predictions for 1UHG_-1000000A\n",
      "Could not find predictions for 1WQ5_-1000000A\n",
      "Could not find predictions for 1WQ5_-1000000G\n",
      "Could not find predictions for 1WQ5_-1000000K\n",
      "Could not find predictions for 1WQ5_-1000000Q\n",
      "Could not find predictions for 2O9P_373R\n",
      "Could not find predictions for 2WSY_-1000000A\n",
      "Could not find predictions for 3D2A_112P\n",
      "Could not find predictions for 3D2A_130D\n",
      "Could not find predictions for 3D2A_155M\n",
      "Could not find predictions for 4E5K_130K\n",
      "Could not find predictions for 4E5K_130Q\n",
      "Could not find predictions for 4E5K_130R\n",
      "Could not find predictions for 4E5K_132K\n",
      "Could not find predictions for 4E5K_132R\n",
      "Could not find predictions for 4E5K_137H\n",
      "Could not find predictions for 4E5K_137R\n",
      "Could not find predictions for 4E5K_150F\n",
      "Could not find predictions for 4E5K_215L\n",
      "Could not find predictions for 4E5K_215M\n",
      "Could not find predictions for 4E5K_275L\n",
      "Could not find predictions for 4E5K_275Q\n",
      "Could not find predictions for 4E5K_276C\n",
      "Could not find predictions for 4E5K_276H\n",
      "Could not find predictions for 4E5K_276Q\n",
      "Could not find predictions for 4E5K_276R\n",
      "Could not find predictions for 4E5K_276S\n",
      "Could not find predictions for 4E5K_313L\n",
      "Could not find predictions for 4E5K_315A\n",
      "Could not find predictions for 4E5K_319E\n",
      "Could not find predictions for 4E5K_325V\n",
      "Could not find predictions for 4E5K_71I\n",
      "Could not find predictions for 6BQG_352N\n"
     ]
    }
   ],
   "source": [
    "import analysis_utils\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "import copy\n",
    "\n",
    "# open each of the main dataset inference files\n",
    "for file1 in ['../data/inference/s461_mapped_preds.csv',\n",
    "              '../data/inference/ssym_mapped_preds.csv',\n",
    "              '../data/inference/korpm_mapped_preds.csv',\n",
    "              '../data/inference/korpm_full_mapped_preds.csv', \n",
    "              '../data/inference/q3421_mapped_preds.csv',\n",
    "              '../data/inference/fireprot_mapped_preds.csv']:  \n",
    "\n",
    "    dataset = file1.split('/')[-1].split('_mapped')[0]\n",
    "    print(dataset)\n",
    "\n",
    "    db = pd.read_csv(file1, index_col=0)\n",
    "    # two entries get inexplicably duplicated in korpm datasets\n",
    "    # but only two inconsequential columns are different\n",
    "    db = db.loc[~db.index.duplicated(keep='last')]\n",
    "\n",
    "    db['uid2'] = db['code'] + '_' + db['position'].fillna(-1000000).astype(int).astype(str) + db['mutation']\n",
    "    \n",
    "    db2 = pd.read_csv(file1.replace('_preds', '').replace('inference', 'preprocessed'), index_col=0)\n",
    "    print(len(db), len(db2))\n",
    "    #assert len(db) == len(db2)\n",
    "\n",
    "    # add the (organism superfamily) origin column if missing\n",
    "    if not 'origin' in db.columns and dataset!='fireprot':\n",
    "        db = db.join(db2['origin'])\n",
    "    elif not 'origin' in db.columns:\n",
    "        db['origin'] = list(db2['origin'])\n",
    "\n",
    "    # replace the cartesian_ddg predictions in case they were updated\n",
    "    if 'cartesian_ddg_dir' in db.columns:\n",
    "        db = db.drop(['cartesian_ddg_dir', 'runtime_cartesian_ddg_dir'], axis=1)\n",
    "    if 'Unnamed: 0' in db.columns:\n",
    "        db = db.drop(['Unnamed: 0'], axis=1)\n",
    "    \n",
    "    db_runtimes = db[[c for c in db.columns if 'runtime' in c or 'uid2' == c]]\n",
    "\n",
    "    db = db.reset_index().rename({'uid': 'uid_'}, axis=1).rename({'uid2': 'uid'}, axis=1).set_index('uid')\n",
    "    # extract the runtimes for methods that have it (not currently used)\n",
    "    db_runtimes = db_runtimes.reset_index().rename({'uid': 'uid_'}, axis=1).rename({'uid2': 'uid'}, axis=1).set_index('uid')\n",
    "    # assuming you have designated the repo location as the path\n",
    "    df_cart, df_cart_runtimes = analysis_utils.parse_rosetta_predictions(db, os.path.join('..', 'data', 'rosetta_predictions'), runtime=True)\n",
    "    \n",
    "    db_mod = db.copy(deep=True)\n",
    "\n",
    "    # juggle the indices if needed\n",
    "\n",
    "    db_mod = db_mod.join(df_cart.astype(float), how='left')\n",
    "    db_mod = db_mod.join(df_cart_runtimes[['runtime_cartesian_ddg_dir']], how='left')\n",
    "    db_mod.index.name = 'uid'\n",
    "    db_mod = db_mod.reset_index().rename({'uid': 'uid2'}, axis=1).rename({'uid_': 'uid'}, axis=1).set_index(['uid', 'uid2'])\n",
    "\n",
    "    db_mod.to_csv(file1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next, add the features that will be used in analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute all pairs of structures and sequences (for running FATCAT and MMSeqs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "728\n",
      "386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2482202/925545498.py:6: DtypeWarning: Columns (42) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  fireprot = pd.read_csv('../data/preprocessed/fireprot_mapped.csv', index_col=0)\n"
     ]
    }
   ],
   "source": [
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio import SeqIO\n",
    "\n",
    "# load the original mapped databases (from preprocessing)\n",
    "fireprot = pd.read_csv('../data/preprocessed/fireprot_mapped.csv', index_col=0)\n",
    "#s461 = pd.read_csv('../data/preprocessed/s461_mapped.csv', index_col=0)\n",
    "s669 = pd.read_csv('../data/preprocessed/s669_mapped.csv', index_col=0)\n",
    "q3421 = pd.read_csv('../data/preprocessed/q3421_mapped.csv', index_col=0)\n",
    "ssym = pd.read_csv('../data/preprocessed/ssym_mapped.csv', index_col=0)\n",
    "korpm = pd.read_csv('../data/preprocessed/korpm_full_mapped.csv', index_col=0)\n",
    "\n",
    "all_structs = set()\n",
    "all_seqs = {}\n",
    "\n",
    "# add the unique structures from each database to a set\n",
    "for df in [fireprot, s669, q3421, korpm]:\n",
    "    df['structure'] = df['code'] + '_' + df['chain']\n",
    "    for s in df['structure'].unique():\n",
    "        all_structs.add(s)\n",
    "        seq = open(f'../sequences/fasta_wt/{s}_PDB.fa', 'r').readlines()[-1]\n",
    "        all_seqs.update({s: seq})\n",
    "\n",
    "# for ssym, we are only going to use the forward (not reverse/mutant) structures \n",
    "\n",
    "ssym['structure'] = ssym['wt_code'] + '_' + ssym['chain']\n",
    "for s in ssym.loc[ssym['wt_code']==ssym['code']]['structure'].unique():\n",
    "    all_structs.add(s)\n",
    "    seq = open(f'../sequences/fasta_wt/{s}_PDB.fa', 'r').readlines()[-1]\n",
    "    all_seqs.update({s: seq})\n",
    "\n",
    "\n",
    "sorted_seqs = {key: all_seqs[key] for key in sorted(all_seqs)}\n",
    "\n",
    "# Convert each tuple to a SeqRecord object, wrapping lines at 80 characters\n",
    "seq_records = [SeqRecord(Seq(seq), id=name, description=\"\") for name, seq in sorted_seqs.items()]\n",
    "\n",
    "# Write the sequences to a FASTA file\n",
    "with open('../data/all_seqs.fasta', 'w') as output_handle:\n",
    "    SeqIO.write(seq_records, output_handle, 'fasta')\n",
    "\n",
    "#with open('../data/all_seqs.fasta', 'w') as f: \n",
    "    #for name, seq in sorted_seqs.items():\n",
    "    #    f.write('>'+name+'\\n')\n",
    "    #    f.write(seq+'\\n')\n",
    "\n",
    "# make a separate set that does include the mutant structures as well\n",
    "all_structs_mutant = copy.deepcopy(all_structs)\n",
    "\n",
    "# add the mutant structures to this\n",
    "ssym['structure2'] = ssym['code'] + '_' + ssym['chain']\n",
    "for s in ssym['structure2'].unique():\n",
    "    all_structs_mutant.add(s)\n",
    "\n",
    "# make a sorted list from the set\n",
    "all_structs_mutant = sorted(list(all_structs_mutant))\n",
    "all_structs_mutant = [s[:4] for s in all_structs_mutant]\n",
    "print(len(all_structs_mutant))\n",
    "\n",
    "# save to a convenience file that shows all PDBs used in this study\n",
    "with open('../data/all_structs.txt', 'w') as f:\n",
    "    for struct1 in all_structs_mutant:\n",
    "       f.write(f'{struct1}\\n') \n",
    "\n",
    "# make a sorted list of the wild-type structures\n",
    "all_structs = sorted(list(all_structs))\n",
    "print(len(all_structs))\n",
    "\n",
    "# match each structure to each other for FATCAT structural alignment\n",
    "with open('../data/all_pairs.txt', 'w') as f:    \n",
    "    for struct1 in all_structs:\n",
    "        for struct2 in all_structs:\n",
    "            if struct1 != struct2:\n",
    "                f.write(f'{struct1} {struct2}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse results from FATCAT (expected at ../data/homology/structural_homology.aln)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       code_1 chain_1 code_2 chain_2  P-value  Afp-num  Identity (%)  \\\n",
      "0        12CA       A   1A0F       A    0.935    11638          3.64   \n",
      "1        12CA       A   1A23       A    0.915    12178          6.28   \n",
      "2        12CA       A   1A43       A    0.812     4097          0.00   \n",
      "3        12CA       A   1A5E       A    0.985    11157          2.44   \n",
      "4        12CA       A   1A7V       A    0.885     7372          1.77   \n",
      "...       ...     ...    ...     ...      ...      ...           ...   \n",
      "148597   9RNT       A   6BQG       A    0.632     6965          4.00   \n",
      "148598   9RNT       A   6G4B       A    0.777    11756          2.78   \n",
      "148599   9RNT       A   6JHM       A    0.898    12418          2.05   \n",
      "148600   9RNT       A   6TQ3       A    0.709     6783          5.76   \n",
      "148601   9RNT       A   8TIM       A    0.480     6552          4.08   \n",
      "\n",
      "        Similarity (%)  \n",
      "0                 9.09  \n",
      "1                12.57  \n",
      "2                 0.00  \n",
      "3                 7.32  \n",
      "4                 8.85  \n",
      "...                ...  \n",
      "148597           12.00  \n",
      "148598            4.17  \n",
      "148599            6.16  \n",
      "148600           12.95  \n",
      "148601           10.20  \n",
      "\n",
      "[148602 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "# Function to parse a line with PDB codes and chains\n",
    "def parse_pdb_line(line):\n",
    "    parts = line.split()\n",
    "    try:\n",
    "        code_1, code_2 = parts[1], parts[4]\n",
    "        chain_1, chain_2 = 'Unknown', 'Unknown'  # Default values\n",
    "        if '_' in code_1:\n",
    "            chain_1 = code_1.split('_')[1].replace('.pdb', '')\n",
    "            code_1 = code_1.split('_')[0]\n",
    "        if '_' in code_2:\n",
    "            chain_2 = code_2.split('_')[1].replace('.pdb', '')\n",
    "            code_2 = code_2.split('_')[0]\n",
    "        return code_1, chain_1, code_2, chain_2\n",
    "    except IndexError as e:\n",
    "        print(f\"Error processing line: {line}\")\n",
    "        raise e\n",
    "\n",
    "# Function to extract values from the line with P-value, Afp-num, etc.\n",
    "def parse_values_line(line):\n",
    "    p_value = float(re.search(r'P-value (\\S+)', line).group(1))\n",
    "    afp_num = int(re.search(r'Afp-num (\\d+)', line).group(1))\n",
    "    identity = float(re.search(r'Identity (\\S+%)', line).group(1).strip('%'))\n",
    "    similarity = float(re.search(r'Similarity (\\S+%)', line).group(1).strip('%'))\n",
    "    return p_value, afp_num, identity, similarity\n",
    "\n",
    "# Read the file and process it\n",
    "data = []\n",
    "with open('../data/homology/structural_homology.aln', 'r') as file:\n",
    "    for line in file:\n",
    "        if line.startswith('Align'):\n",
    "            #print(line)\n",
    "            code_1, chain_1, code_2, chain_2 = parse_pdb_line(line)\n",
    "        if 'P-value' in line:\n",
    "            p_value, afp_num, identity, similarity = parse_values_line(line)\n",
    "            data.append([code_1, chain_1, code_2, chain_2, p_value, afp_num, identity, similarity])\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data, columns=['code_1', 'chain_1', 'code_2', 'chain_2', 'P-value', 'Afp-num', 'Identity (%)', 'Similarity (%)'])\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine which datasets have identical mutants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2482202/2006045167.py:2: DtypeWarning: Columns (42) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  fireprot = list(pd.read_csv('../data/preprocessed/fireprot_mapped.csv')['code'].unique())\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code_1</th>\n",
       "      <th>chain_1</th>\n",
       "      <th>code_2</th>\n",
       "      <th>chain_2</th>\n",
       "      <th>P-value</th>\n",
       "      <th>Afp-num</th>\n",
       "      <th>Identity (%)</th>\n",
       "      <th>Similarity (%)</th>\n",
       "      <th>datasets_1</th>\n",
       "      <th>datasets_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12CA_A</td>\n",
       "      <td>A</td>\n",
       "      <td>1A0F_A</td>\n",
       "      <td>A</td>\n",
       "      <td>0.935</td>\n",
       "      <td>11638</td>\n",
       "      <td>3.64</td>\n",
       "      <td>9.09</td>\n",
       "      <td>['korpm', 'korpm_full']</td>\n",
       "      <td>['s461', 's669']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12CA_A</td>\n",
       "      <td>A</td>\n",
       "      <td>1A23_A</td>\n",
       "      <td>A</td>\n",
       "      <td>0.915</td>\n",
       "      <td>12178</td>\n",
       "      <td>6.28</td>\n",
       "      <td>12.57</td>\n",
       "      <td>['korpm', 'korpm_full']</td>\n",
       "      <td>['fireprot', 'q3421', 'korpm', 'korpm_full']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12CA_A</td>\n",
       "      <td>A</td>\n",
       "      <td>1A43_A</td>\n",
       "      <td>A</td>\n",
       "      <td>0.812</td>\n",
       "      <td>4097</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>['korpm', 'korpm_full']</td>\n",
       "      <td>['fireprot', 'q3421']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12CA_A</td>\n",
       "      <td>A</td>\n",
       "      <td>1A5E_A</td>\n",
       "      <td>A</td>\n",
       "      <td>0.985</td>\n",
       "      <td>11157</td>\n",
       "      <td>2.44</td>\n",
       "      <td>7.32</td>\n",
       "      <td>['korpm', 'korpm_full']</td>\n",
       "      <td>['fireprot', 'q3421', 'korpm', 'korpm_full']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12CA_A</td>\n",
       "      <td>A</td>\n",
       "      <td>1A7V_A</td>\n",
       "      <td>A</td>\n",
       "      <td>0.885</td>\n",
       "      <td>7372</td>\n",
       "      <td>1.77</td>\n",
       "      <td>8.85</td>\n",
       "      <td>['korpm', 'korpm_full']</td>\n",
       "      <td>['s669', 'korpm', 'korpm_full']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148597</th>\n",
       "      <td>9RNT_A</td>\n",
       "      <td>A</td>\n",
       "      <td>6BQG_A</td>\n",
       "      <td>A</td>\n",
       "      <td>0.632</td>\n",
       "      <td>6965</td>\n",
       "      <td>4.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>['korpm_full']</td>\n",
       "      <td>['fireprot']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148598</th>\n",
       "      <td>9RNT_A</td>\n",
       "      <td>A</td>\n",
       "      <td>6G4B_A</td>\n",
       "      <td>A</td>\n",
       "      <td>0.777</td>\n",
       "      <td>11756</td>\n",
       "      <td>2.78</td>\n",
       "      <td>4.17</td>\n",
       "      <td>['korpm_full']</td>\n",
       "      <td>['fireprot']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148599</th>\n",
       "      <td>9RNT_A</td>\n",
       "      <td>A</td>\n",
       "      <td>6JHM_A</td>\n",
       "      <td>A</td>\n",
       "      <td>0.898</td>\n",
       "      <td>12418</td>\n",
       "      <td>2.05</td>\n",
       "      <td>6.16</td>\n",
       "      <td>['korpm_full']</td>\n",
       "      <td>['fireprot']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148600</th>\n",
       "      <td>9RNT_A</td>\n",
       "      <td>A</td>\n",
       "      <td>6TQ3_A</td>\n",
       "      <td>A</td>\n",
       "      <td>0.709</td>\n",
       "      <td>6783</td>\n",
       "      <td>5.76</td>\n",
       "      <td>12.95</td>\n",
       "      <td>['korpm_full']</td>\n",
       "      <td>['fireprot']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148601</th>\n",
       "      <td>9RNT_A</td>\n",
       "      <td>A</td>\n",
       "      <td>8TIM_A</td>\n",
       "      <td>A</td>\n",
       "      <td>0.480</td>\n",
       "      <td>6552</td>\n",
       "      <td>4.08</td>\n",
       "      <td>10.20</td>\n",
       "      <td>['korpm_full']</td>\n",
       "      <td>['fireprot']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>148602 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        code_1 chain_1  code_2 chain_2  P-value  Afp-num  Identity (%)  \\\n",
       "0       12CA_A       A  1A0F_A       A    0.935    11638          3.64   \n",
       "1       12CA_A       A  1A23_A       A    0.915    12178          6.28   \n",
       "2       12CA_A       A  1A43_A       A    0.812     4097          0.00   \n",
       "3       12CA_A       A  1A5E_A       A    0.985    11157          2.44   \n",
       "4       12CA_A       A  1A7V_A       A    0.885     7372          1.77   \n",
       "...        ...     ...     ...     ...      ...      ...           ...   \n",
       "148597  9RNT_A       A  6BQG_A       A    0.632     6965          4.00   \n",
       "148598  9RNT_A       A  6G4B_A       A    0.777    11756          2.78   \n",
       "148599  9RNT_A       A  6JHM_A       A    0.898    12418          2.05   \n",
       "148600  9RNT_A       A  6TQ3_A       A    0.709     6783          5.76   \n",
       "148601  9RNT_A       A  8TIM_A       A    0.480     6552          4.08   \n",
       "\n",
       "        Similarity (%)               datasets_1  \\\n",
       "0                 9.09  ['korpm', 'korpm_full']   \n",
       "1                12.57  ['korpm', 'korpm_full']   \n",
       "2                 0.00  ['korpm', 'korpm_full']   \n",
       "3                 7.32  ['korpm', 'korpm_full']   \n",
       "4                 8.85  ['korpm', 'korpm_full']   \n",
       "...                ...                      ...   \n",
       "148597           12.00           ['korpm_full']   \n",
       "148598            4.17           ['korpm_full']   \n",
       "148599            6.16           ['korpm_full']   \n",
       "148600           12.95           ['korpm_full']   \n",
       "148601           10.20           ['korpm_full']   \n",
       "\n",
       "                                          datasets_2  \n",
       "0                                   ['s461', 's669']  \n",
       "1       ['fireprot', 'q3421', 'korpm', 'korpm_full']  \n",
       "2                              ['fireprot', 'q3421']  \n",
       "3       ['fireprot', 'q3421', 'korpm', 'korpm_full']  \n",
       "4                    ['s669', 'korpm', 'korpm_full']  \n",
       "...                                              ...  \n",
       "148597                                  ['fireprot']  \n",
       "148598                                  ['fireprot']  \n",
       "148599                                  ['fireprot']  \n",
       "148600                                  ['fireprot']  \n",
       "148601                                  ['fireprot']  \n",
       "\n",
       "[148602 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the unique structures from each dataset\n",
    "fireprot = list(pd.read_csv('../data/preprocessed/fireprot_mapped.csv')['code'].unique())\n",
    "s461 = list(pd.read_csv('../data/preprocessed/s461_mapped.csv')['code'].unique())\n",
    "s669 = list(pd.read_csv('../data/preprocessed/s669_mapped.csv')['code'].unique())\n",
    "q3421 = list(pd.read_csv('../data/preprocessed/q3421_mapped.csv')['code'].unique())\n",
    "ssym = list(pd.read_csv('../data/preprocessed/ssym_mapped.csv')['code'].unique())\n",
    "korpm_reduced = list(pd.read_csv('../data/preprocessed/korpm_mapped.csv')['code'].unique())\n",
    "korpm_full = list(pd.read_csv('../data/preprocessed/korpm_full_mapped.csv')['code'].unique())\n",
    "\n",
    "datasets = ['fireprot', 's461', 's669', 'q3421', 'ssym', 'korpm', 'korpm_full'] #'s669', \n",
    "df['datasets_1'] = [[] for _ in range(len(df))]\n",
    "df['datasets_2'] = [[] for _ in range(len(df))]\n",
    "\n",
    "# Iterate over each dataset and update the DataFrame\n",
    "for name, codes in zip(datasets, [fireprot, s461, s669, q3421, ssym, korpm_reduced, korpm_full]): #s669,\n",
    "    for i in df.index:\n",
    "        if df.at[i, 'code_1'] in codes:\n",
    "            df.at[i, 'datasets_1'].append(name)\n",
    "        if df.at[i, 'code_2'] in codes:\n",
    "            df.at[i, 'datasets_2'].append(name)\n",
    "\n",
    "df['datasets_1'] = df['datasets_1'].astype(str)\n",
    "df['datasets_2'] = df['datasets_2'].astype(str)\n",
    "df = df.loc[(df['datasets_1'].astype(str)!='[]') & (df['datasets_2'].astype(str)!='[]')]\n",
    "#df.sort_values('Similarity (%)', ascending=False).head(50)\n",
    "\n",
    "df['code_1'] = df['code_1'] + '_' + df['chain_1']\n",
    "df['code_2'] = df['code_2'] + '_' + df['chain_2']\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine which datasets have mutants with significant structural homology, forming clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fireprot protein clusters based on similarity:\n",
      "123\n",
      "[['1C9O_A', '1MJC_A', '1CSP_A'], ['1QJP_A', '1RBP_A', '1B0O_A', '2CBR_A', '1IFB_A', '2HMB_A'], ['1FEP_A'], ['1AJ3_A', '1RHG_A', '1LS4_A', '1N0J_A', '2BRD_A', '2Q98_A', '1ROP_A'], ['1OIA_A', '1RIS_A', '1APS_A', '2HPR_A'], ['2DRI_A', '1LUC_A', '1ADO_A', '1WQ5_A', '1BTM_A'], ['1DKT_A', '1SCE_A'], ['1H0C_A', '1AMQ_A', '6G4B_A'], ['1BLC_A', '3BLS_A', '4BLM_A', '1AXB_A'], ['1PX0_A', '6TQ3_A', '2CHF_A'], ['5CRO_O', '1ARR_A'], ['1IR3_A', '1FMK_A'], ['1BCX_A', '3WP4_A', '1H8V_A', '1OLR_A'], ['5AZU_A'], ['3MBP_A'], ['1B5M_A', '1CYO_A', '1IET_A'], ['1ANK_A', '2AKY_A'], ['1DIV_A', '2ZTA_A'], ['1JU3_A', '1EVQ_A', '1MJ5_A', '1CQW_A'], ['3PG4_A'], ['1BNI_A', '1MGR_A', '1RGG_A', '1RN1_C'], ['1ZNJ_A'], ['3D2A_A', '1PDO_A'], ['1E21_A', '1ONC_A', '1RTB_A'], ['1CF3_A'], ['1HFY_A', '1HFZ_A', '4LYZ_A', '1LZ1_A', '1EL1_A'], ['1AZP_A', '1C8C_A', '1SSO_A'], ['1BAH_A'], ['1BTA_A'], ['1HZ6_A', '1UBQ_A', '1PGA_A', '1OTR_B'], ['1B26_A', '1LBI_A'], ['2HIP_A'], ['1BRF_A', '1IRO_A'], ['1YPI_A', '1TPE_A', '2O9P_A', '1HTI_A', '2WSY_A', '1TUX_A', '1I4N_A', '8TIM_A'], ['4E5K_A'], ['1CAH_A'], ['5ZYR_A'], ['1CTS_A', '6BQG_A'], ['1K9Q_A'], ['1QM4_A'], ['1TIT_A', '2IMM_A', '1HNG_A', '1LVE_A', '1TEN_A', '1WIT_A'], ['1CYC_A', '1YCC_A', '1C2R_A', '451C_A', '1YEA_A', '1AKK_A', '1YNR_A'], ['2CPP_A'], ['1KFW_A'], ['1DPM_A', '1XAS_A'], ['2LZM_A', '1YYX_A'], ['1C5G_A', '1UHG_A', '1ANT_L', '1QLP_A'], ['1FXA_A', '1AYF_A', '1AAR_A', '1FRD_A', '1AYF_B'], ['1AYE_A'], ['1SUP_A'], ['1LRP_A', '1UZC_A'], ['4ZLU_A'], ['1TPK_A', '1URK_A'], ['1ZYM_A', '1DKG_A', '1BVC_A', '3HHR_A'], ['1AG2_A', '1UWO_A'], ['1AV1_A'], ['2UXY_A'], ['2RN2_A', '1IO2_A'], ['1STN_A'], ['1G6N_A'], ['1ZNJ_B', '1MBG_A'], ['1AM7_A'], ['3VUB_A', '2A36_A'], ['1BYW_A'], ['1DEC_A'], ['1JK9_A'], ['2TRX_A', '1QGV_A', '1H7M_A'], ['1KEV_A'], ['1AON_O'], ['1BVU_A'], ['1BFG_A', '2AFG_A', '1IOB_A', '3PG0_A'], ['1RX4_A'], ['1IDS_A'], ['1IGV_A', '1RRO_A', '1RTP_1'], ['2ADA_A'], ['1TTG_A', '1BOY_A'], ['2CRK_A'], ['1QND_A'], ['1JIW_I'], ['1FTG_A'], ['1TUP_A'], ['1HUE_A', '2TRT_A'], ['1BNL_A'], ['1DIL_A'], ['2CI2_I', '1TIN_A', '1ACB_I'], ['2TS1_A'], ['1P2P_A', '1BP2_A'], ['1QGD_A'], ['1HYN_P'], ['1QQV_A'], ['1JNX_X'], ['1MSI_A'], ['1FKJ_A'], ['1TCA_A'], ['1C52_A'], ['1CHK_A'], ['1FC1_A'], ['1KA6_A'], ['3PGK_A'], ['1SHF_A'], ['3TGL_A'], ['3SSI_A'], ['1HK0_X'], ['1VQB_A'], ['1BPI_A'], ['1GUY_C'], ['1IMQ_A'], ['1HME_A'], ['1THQ_A', '1OH0_A'], ['1AQH_A'], ['1W4E_A'], ['1TDJ_A'], ['1M21_A'], ['2ABD_A'], ['1PIN_A'], ['1CLW_A'], ['1A5E_A', '1IHB_A', '1SVX_A'], ['1A23_A'], ['1A43_A'], ['1CEY_A'], ['1POH_A'], ['1KCQ_A'], ['6JHM_A']]\n",
      "s461 protein clusters based on similarity:\n",
      "39\n",
      "[['1N88_A'], ['1BNL_A'], ['1BA3_A'], ['1FRD_A', '1FXA_A', '1GUA_B'], ['1ITM_A', '1A0F_A'], ['1IOJ_A'], ['2HBB_A', '1DIV_A'], ['2WQG_A', '2ZTA_A'], ['3BN0_A'], ['5JXB_A'], ['2M5S_A'], ['2H3F_A'], ['1JLV_A'], ['3C2I_A'], ['2C9Q_A'], ['1EKG_A', '3S4M_A'], ['1XXN_A'], ['2LTB_A'], ['2PTL_A'], ['1BFM_A'], ['1IV7_A', '3MON_B', '1IV9_A'], ['3L15_A', '5OAQ_A'], ['4BUQ_A'], ['1JL9_A'], ['1O6X_A'], ['1G3P_A'], ['2NTE_A'], ['1NM1_A'], ['1H0X_A'], ['1FT8_A'], ['1L6H_A'], ['1J8I_A'], ['3D3B_A'], ['1R2Y_A'], ['3DV0_I'], ['1LVM_A'], ['2N7Z_A'], ['4HE7_A'], ['2ARF_A']]\n",
      "s669 protein clusters based on similarity:\n",
      "64\n",
      "[['1BNL_A'], ['2DVV_A', '3S92_A', '2OUO_A', '1X0J_A', '4BJX_A', '2N7Z_A'], ['1XWS_A', '1IR3_A'], ['3BN0_A'], ['2M5S_A'], ['2H3F_A', '3FIS_A'], ['1JLV_A', '1A0F_A'], ['1F8I_A'], ['2LTB_A'], ['1DIV_A', '2ZTA_A'], ['2KS4_A', '1GWY_A'], ['5VP3_A'], ['3MON_B', '4N6V_2', '1IV7_A', '1IV9_A'], ['3D2A_A', '1H0X_A'], ['1G3P_A'], ['1FH5_H', '1FH5_L', '2CLR_B'], ['2JUC_A'], ['2NTE_A'], ['3BCI_A', '3D3B_A'], ['2VY0_A'], ['3O39_A', '3S4M_A'], ['4YEF_A', '4YEE_A'], ['1FT8_A'], ['1GLU_A', '1HCQ_A'], ['1PRE_A'], ['3DV0_I'], ['5OAQ_A', '3L15_A'], ['3K82_A', '5JXB_A', '1D5G_A'], ['2ARF_A'], ['1R6R_A', '1BFM_A'], ['1PFL_A'], ['3G1G_A'], ['1N88_A'], ['1BA3_A'], ['1OSI_A'], ['1FRD_A', '1FXA_A', '1GUA_B'], ['1ITM_A', '1A7V_A'], ['1IOJ_A'], ['1XZO_A'], ['2HBB_A'], ['2KJ3_A'], ['2WQG_A'], ['1N18_A', '3ECU_A', '1SPD_A'], ['3C2I_A'], ['2MPC_A'], ['2C9Q_A'], ['1EKG_A', '1O1U_A'], ['4WAA_A'], ['2RPN_A'], ['1XXN_A'], ['2PTL_A', '2BJD_A'], ['4BUQ_A'], ['2JIE_A'], ['1JL9_A'], ['1O6X_A'], ['1NM1_A'], ['1L6H_A'], ['1DXX_A'], ['1J8I_A'], ['1R2Y_A'], ['1LVM_A'], ['4HE7_A'], ['1PRG_A'], ['2PR5_A']]\n",
      "q3421 protein clusters based on similarity:\n",
      "80\n",
      "[['1FTG_A', '1FLV_A'], ['1TUP_A'], ['1BNL_A'], ['1C9O_A', '1MJC_A', '1CSP_A'], ['1QJP_A', '2IFB_A', '1IFB_A', '2HMB_A', '1B0O_A'], ['1FEP_A'], ['1DIL_A'], ['1AJ3_A', '1RHG_A', '2Q98_A', '1LS4_A', '1BVC_A', '1AV1_A', '1ROP_A', '2BRD_A', '3HHR_A'], ['1OIA_A', '1APS_A', '2HPR_A', '1RIS_A'], ['2CI2_I'], ['1DKT_A', '1SCE_A'], ['1BLC_A', '4BLM_A', '3BLS_A', '1AXB_A'], ['5CRO_O', '1ARR_A'], ['1IR3_A'], ['5AZU_A'], ['1MBG_A', '2ZTA_A', '1ZNJ_B'], ['1RRO_A', '1RTP_1', '1UWO_A', '1IGV_A'], ['3MBP_A'], ['1B5M_A', '1CYO_A'], ['1QQV_A'], ['1ANK_A', '2AKY_A'], ['1BOY_A', '1FNF_A', '1TEN_A', '1TTG_A'], ['1MSI_A'], ['1FKJ_A'], ['1DIV_A'], ['1C2R_A', '451C_A', '1CYC_A', '1YCC_A', '1YEA_A', '1AKK_A', '1I5T_A'], ['1QGV_A', '1H7M_A', '2TRX_A'], ['1BNI_A', '1RGG_A', '1RN1_C'], ['1ZNJ_A'], ['1IRO_A'], ['3D2A_A'], ['1HFY_A', '4LYZ_A', '1LZ1_A', '1EL1_A'], ['1AZP_A', '1SSO_A'], ['1BTA_A'], ['1CHK_A'], ['1SAK_A', '1KDX_A'], ['2WSY_A', '1WQ5_A', '1HTI_A'], ['1B26_A'], ['1W4H_A'], ['1OTR_B', '1AAR_A', '1FXA_A', '1UBQ_A', '1AYF_A', '1AYF_B'], ['1QLP_A', '1C5G_A'], ['1N0J_A', '1IDS_A'], ['1CAH_A'], ['2AFG_A', '1IOB_A'], ['1L63_A', '2LZM_A'], ['1HNG_A', '1TIT_A', '1LVE_A', '2IMM_A'], ['3PGK_A'], ['1SHF_A', '1SHG_A', '2A36_A'], ['3SSI_A'], ['1AMQ_A'], ['1KFW_A'], ['1HK0_X'], ['1DPM_A', '2ADA_A'], ['1VQB_A'], ['1BPI_A'], ['1FRD_A'], ['1IMQ_A'], ['1HME_A'], ['1SUP_A'], ['1THQ_A', '1OH0_A'], ['1TPK_A'], ['1AG2_A', '1A43_A'], ['2RN2_A', '1IO2_A'], ['1ONC_A', '1RTB_A'], ['1STN_A'], ['1G6N_A'], ['2ABD_A'], ['1AM7_A'], ['1PIN_A'], ['1CLW_A'], ['1A5E_A', '1IHB_A'], ['1A23_A'], ['1PGA_A'], ['1BP2_A'], ['1UZC_A'], ['1AON_O'], ['1RX4_A'], ['1CEY_A'], ['1POH_A'], ['2CRK_A']]\n",
      "ssym protein clusters based on similarity:\n",
      "12\n",
      "[['2LZM_A', '1L63_A'], ['1BNI_A', '1RN1_C'], ['1IHB_A'], ['4LYZ_A', '1LZ1_A'], ['2RN2_A'], ['1EY0_A'], ['1OH0_A'], ['5PTI_A'], ['1CEY_A'], ['1IOB_A'], ['1AMQ_A'], ['1VQB_A']]\n",
      "korpm protein clusters based on similarity:\n",
      "97\n",
      "[['1C9O_A', '1MJC_A', '1CSP_A'], ['1BTL_A', '1AXB_A'], ['1AJ3_A', '1AYI_A', '2SPZ_A'], ['1OIA_A', '1Y4Y_A', '1RIS_A', '2K7J_A', '1APS_A', '2HPR_A', '2BJD_A'], ['2DRI_A', '1FTG_A'], ['1DKT_A'], ['2JOF_A'], ['1NFI_F', '1A5E_A', '1IHB_A'], ['1RHG_A', '2H3F_A', '1LPE_A'], ['3MBP_A'], ['1B5M_A'], ['1U4Q_A', '1LS4_A', '2Q98_A', '1BVC_A', '1A7V_A'], ['3BDC_A', '1STN_A'], ['2LTB_A'], ['1DIV_A', '1XYX_A'], ['2MMX_A', '1FH5_H', '1FH5_L', '1TIT_A', '2IMM_A', '1OPG_L', '1LVE_A'], ['5VP3_A', '1CFD_A', '1IGV_A', '1RRO_A'], ['1BNI_A', '1MGR_A', '1RGG_A', '1RN1_C'], ['3D2A_A'], ['2JUC_A', '1AM7_A'], ['1HFY_A', '1HFZ_A', '4LYZ_A', '1LZ1_A', '1EL1_A'], ['2NTE_A', '1JNX_X'], ['1JY0_A', '1K5U_A', '1JQZ_A', '2AFG_A', '1IOB_A'], ['1AZP_A', '1J8I_A', '1BNZ_A'], ['1BTA_A'], ['5TR5_A', '1UBQ_A'], ['1W4H_A', '3DV0_I'], ['1CAH_A', '12CA_A'], ['1L63_A', '2LZM_A'], ['3S4M_A', '1IV9_A', '2IFB_A'], ['3G1G_A', '1AG2_A'], ['1CYC_A', '1YCC_A', '1I5T_A', '1C2R_A', '451C_A', '1AKK_A'], ['1KFW_A'], ['2AKY_A'], ['1N88_A'], ['1BA3_A'], ['1ITM_A', '1B10_A'], ['1IOJ_A', '1HME_A'], ['1FXA_A'], ['5T43_A', '1THQ_A'], ['1RIL_A', '2RN2_A', '1IO2_A'], ['1SUP_A'], ['1TPK_A'], ['1SHG_A', '2RPN_A', '2A36_A'], ['3C2I_A'], ['2MPC_A'], ['1E0L_A', '2ZAJ_A', '4GWT_A'], ['1ONC_A', '1RTB_A'], ['1FKB_A', '1FKJ_A'], ['1XXN_A'], ['2RN4_A'], ['1Z1I_A'], ['3L15_A', '1TTG_A'], ['1O6X_A', '1CM2_A', '1POH_A'], ['1FLV_A'], ['1PGA_A', '2PTL_A'], ['1L6H_A'], ['2TRX_A', '1QGV_A', '1H7M_A'], ['1UZC_A'], ['1RX4_A'], ['1QND_A'], ['2PR5_A'], ['1DIL_A'], ['2CI2_I', '1ACB_I', '1EGL_A'], ['1QM0_A', '2LSB_A'], ['1MBG_A'], ['2K3K_A'], ['1ARR_A', '2WQG_A'], ['1QQV_A', '1VII_A'], ['1MSI_A'], ['2KS4_A', '1GWY_A'], ['2LCP_A'], ['1G3P_A'], ['2WZB_A', '3PGK_A', '5NP8_A'], ['1FT8_A'], ['1CHK_A'], ['1FNF_A', '1K85_A'], ['1WQ5_A'], ['1PRE_A'], ['1QLP_A'], ['2ARF_A'], ['1PFL_A'], ['3SSI_A'], ['1HK0_X'], ['1OSI_A'], ['2IN9_A'], ['1BPI_A'], ['1IMQ_A', '3MXF_A'], ['2HBB_A'], ['2JYS_A'], ['1N18_A'], ['2ABD_A'], ['1IV7_A'], ['1PIN_A'], ['1A23_A'], ['1GLM_A'], ['1CEY_A']]\n",
      "korpm_full protein clusters based on similarity:\n",
      "104\n",
      "[['1C9O_A', '1MJC_A', '1G6P_A', '1CSP_A'], ['1BK7_A'], ['1BTL_A', '1BLC_A', '1AXB_A'], ['1AJ3_A', '1AYI_A', '2SPZ_A'], ['1OIA_A', '1Y4Y_A', '1RIS_A', '2K7J_A', '1APS_A', '2HPR_A', '2BJD_A'], ['2DRI_A', '1FTG_A', '3F6R_A'], ['1DKT_A'], ['2JOF_A'], ['3BN0_A'], ['1NFI_F', '1A5E_A', '1IHB_A'], ['1RHG_A', '2H3F_A', '1LPE_A'], ['1BU4_A', '1BNI_A', '9RNT_A', '1YGW_A', '1MGR_A', '1RGG_A', '1RN1_C'], ['2M5S_A'], ['1IR3_A'], ['3MBP_A'], ['1B5M_A'], ['1U4Q_A', '1LS4_A', '2Q98_A', '1BVC_A', '1A7V_A'], ['3BDC_A', '1STN_A'], ['2LTB_A'], ['1DIV_A', '1XYX_A'], ['2MMX_A', '1FH5_H', '1FH5_L', '1TIT_A', '2IMM_A', '1OPG_L', '1LVE_A', '1WIT_A'], ['5VP3_A', '1CFD_A', '1IGV_A', '1RRO_A'], ['3D2A_A'], ['2JUC_A', '1AM7_A'], ['1HFY_A', '1HFZ_A', '4LYZ_A', '1LZ1_A', '1EL1_A'], ['2NTE_A', '1JNX_X'], ['1JY0_A', '1K5U_A', '1JQZ_A', '2AFG_A', '1IOB_A'], ['1AZP_A', '1J8I_A', '1BNZ_A'], ['1BTA_A'], ['5TR5_A', '1UBQ_A'], ['1W4H_A', '3DV0_I'], ['1CAH_A', '12CA_A'], ['1L63_A', '2LZM_A'], ['2CK2_A', '3L15_A', '1TTG_A', '1TEN_A'], ['3S4M_A', '1IV9_A', '2IFB_A'], ['3G1G_A', '1AG2_A'], ['1CYC_A', '1YCC_A', '1I5T_A', '1C2R_A', '451C_A', '1AKK_A'], ['1KFW_A'], ['2AKY_A'], ['1N88_A'], ['1BA3_A'], ['1ITM_A', '1B10_A'], ['1IOJ_A', '1HME_A'], ['1FXA_A'], ['5T43_A', '1THQ_A'], ['1RIL_A', '2RN2_A', '1IO2_A'], ['1SUP_A'], ['1TPK_A'], ['1YRI_A', '1QQV_A', '1VII_A', '1WY3_A'], ['1SHG_A', '2RPN_A', '2A36_A'], ['3C2I_A'], ['2MPC_A', '2N7Z_A'], ['1E0L_A', '2ZAJ_A', '4GWT_A'], ['1ONC_A', '1RTB_A'], ['1FKB_A', '1FKJ_A'], ['1XXN_A'], ['2RN4_A'], ['1Z1I_A'], ['1O6X_A', '1CM2_A', '1POH_A'], ['1FLV_A'], ['1PGA_A', '2PTL_A'], ['1L6H_A'], ['2TRX_A', '1QGV_A', '1H7M_A'], ['1UZC_A'], ['1RX4_A'], ['1QND_A'], ['2PR5_A'], ['1DIL_A'], ['2CI2_I', '1ACB_I', '1EGL_A'], ['1QM0_A', '2LSB_A', '2N53_A'], ['1MBG_A'], ['2K3K_A'], ['1ARR_A', '2WQG_A'], ['1MSI_A'], ['2KS4_A', '1GWY_A'], ['2LCP_A'], ['3FFN_A'], ['1G3P_A'], ['2WZB_A', '3PGK_A', '5NP8_A'], ['1FT8_A'], ['1CHK_A'], ['1FNF_A', '1K85_A'], ['1WQ5_A'], ['1PRE_A'], ['1QLP_A'], ['2ARF_A'], ['1PFL_A'], ['3SSI_A'], ['1HK0_X'], ['1OSI_A'], ['2IN9_A'], ['1BPI_A'], ['1IMQ_A', '3MXF_A'], ['1XZO_A'], ['2HBB_A'], ['2JYS_A'], ['1N18_A'], ['2ABD_A'], ['1IV7_A'], ['1PIN_A'], ['1A23_A'], ['1GLM_A'], ['1CEY_A'], ['2RLK_A']]\n"
     ]
    }
   ],
   "source": [
    "### cluster based on E-value (structural)\n",
    "from collections import defaultdict\n",
    "\n",
    "def find_cluster(protein, assigned_clusters, threshold=0.01):\n",
    "    for cluster in assigned_clusters:\n",
    "        if all(similarity_matrix.at[protein, member] <= threshold for member in cluster):\n",
    "            return cluster\n",
    "    return None\n",
    "\n",
    "for name, codes in zip(datasets, [fireprot, s461, s669, q3421, ssym, korpm_reduced, korpm_full]):\n",
    "    df_cur = df.copy(deep=True).loc[df['datasets_1'].astype(str).str.contains(f\"\\'{name}\\'\")]\n",
    "    df_cur = df_cur.loc[df['datasets_2'].astype(str).str.contains(f\"\\'{name}\\'\")]\n",
    "    #df_cur = df_cur.loc[df['Similarity (%)']>50]\n",
    "    # Create a list of all unique codes\n",
    "    all_codes = set(df_cur['code_1']).union(set(df_cur['code_2']))\n",
    "\n",
    "    # Pivot to create a similarity matrix\n",
    "    similarity_matrix = df_cur.pivot(index='code_1', columns='code_2', values='P-value')\n",
    "\n",
    "    # Reindex the DataFrame to include all codes in both rows and columns\n",
    "    similarity_matrix = similarity_matrix.reindex(index=all_codes, columns=all_codes)\n",
    "\n",
    "    # Fill NaN values with 0 and make the matrix symmetric\n",
    "    similarity_matrix = similarity_matrix.fillna(0)\n",
    "    similarity_matrix = similarity_matrix + similarity_matrix.T - similarity_matrix.multiply(similarity_matrix.T.gt(0))\n",
    "\n",
    "    # Assign proteins to clusters\n",
    "    clusters = defaultdict(list)\n",
    "    for protein in similarity_matrix.index:\n",
    "        cluster = find_cluster(protein, clusters.values())\n",
    "        if cluster is not None:\n",
    "            cluster.append(protein)\n",
    "        else:\n",
    "            clusters[len(clusters)].append(protein)\n",
    "\n",
    "    # Convert the clusters dictionary to a list for better readability\n",
    "    cluster_list = list(clusters.values())\n",
    "\n",
    "    print(name, \"protein clusters based on similarity:\")\n",
    "    print(len(cluster_list))\n",
    "    print(cluster_list)\n",
    "\n",
    "    data = pd.read_csv(f'../data/inference/{name}_mapped_preds.csv', index_col=0)\n",
    "    if name == 's461':\n",
    "        data['code'] = data.index.str[:4]\n",
    "        \n",
    "    data['cluster'] = 0\n",
    "    i = 0\n",
    "    for clus in cluster_list:\n",
    "        i += 1\n",
    "        for code_ in clus:\n",
    "            code = code_[:4]\n",
    "            chain = code_[-1]\n",
    "            data.loc[(data['code']==code)&(data['chain']==chain), 'cluster'] = i\n",
    "    data.to_csv(f'../data/inference/{name}_mapped_preds_clusters.csv')\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save information for use in the dataset-specific analysis notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fireprot s461\n",
      "fireprot s669\n",
      "fireprot q3421\n",
      "fireprot ssym\n",
      "fireprot korpm\n",
      "fireprot korpm_full\n",
      "s461 fireprot\n",
      "s461 s669\n",
      "s461 q3421\n",
      "s461 ssym\n",
      "s461 korpm\n",
      "s461 korpm_full\n",
      "s669 fireprot\n",
      "s669 s461\n",
      "s669 q3421\n",
      "s669 ssym\n",
      "s669 korpm\n",
      "s669 korpm_full\n",
      "q3421 fireprot\n",
      "q3421 s461\n",
      "q3421 s669\n",
      "q3421 ssym\n",
      "q3421 korpm\n",
      "q3421 korpm_full\n",
      "ssym fireprot\n",
      "ssym s461\n",
      "ssym s669\n",
      "ssym q3421\n",
      "ssym korpm\n",
      "ssym korpm_full\n",
      "korpm fireprot\n",
      "korpm s461\n",
      "korpm s669\n",
      "korpm q3421\n",
      "korpm ssym\n",
      "korpm korpm_full\n",
      "korpm_full fireprot\n",
      "korpm_full s461\n",
      "korpm_full s669\n",
      "korpm_full q3421\n",
      "korpm_full ssym\n",
      "korpm_full korpm\n"
     ]
    }
   ],
   "source": [
    "# detect sequence overlaps > 25% (for structurally defined region)\n",
    "for name1 in datasets:\n",
    "    for name2 in datasets:\n",
    "        if name1 != name2:\n",
    "            print(name1, name2)\n",
    "            ds1 = pd.read_csv(f'../data/inference/{name1}_mapped_preds_clusters.csv', index_col=0)\n",
    "            ds2 = pd.read_csv(f'../data/inference/{name2}_mapped_preds_clusters.csv', index_col=0)\n",
    "            overlap = df.loc[((df['datasets_1'].str.contains(name1)) & (df['datasets_2'].str.contains(name2)) | (df['datasets_1'].str.contains(name2)) & (df['datasets_2'].str.contains(name1))) & (df['Identity (%)']>25)]\n",
    "            overlapping_codes = list(overlap['code_1'].str[:4].unique()) + list(overlap['code_2'].str[:4].unique())\n",
    "            overlapping_codes += list(set(ds1['code'].unique()).intersection(set(ds2['code'].unique())))\n",
    "            ds1[f'{name2}_cluster'] = False\n",
    "            ds2[f'{name1}_cluster'] = False\n",
    "            ds1.loc[ds1['code'].isin(overlapping_codes), f'{name2}_cluster'] = True\n",
    "            ds2.loc[ds2['code'].isin(overlapping_codes), f'{name1}_cluster'] = True\n",
    "            ds1.to_csv(f'../data/inference/{name1}_mapped_preds_clusters.csv')\n",
    "            ds2.to_csv(f'../data/inference/{name2}_mapped_preds_clusters.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code_1</th>\n",
       "      <th>chain_1</th>\n",
       "      <th>code_2</th>\n",
       "      <th>chain_2</th>\n",
       "      <th>P-value</th>\n",
       "      <th>Afp-num</th>\n",
       "      <th>Identity (%)</th>\n",
       "      <th>Similarity (%)</th>\n",
       "      <th>datasets_1</th>\n",
       "      <th>datasets_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12CA_A</td>\n",
       "      <td>A</td>\n",
       "      <td>1A0F_A</td>\n",
       "      <td>A</td>\n",
       "      <td>0.935</td>\n",
       "      <td>11638</td>\n",
       "      <td>3.64</td>\n",
       "      <td>9.09</td>\n",
       "      <td>['korpm', 'korpm_full']</td>\n",
       "      <td>['s461', 's669']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12CA_A</td>\n",
       "      <td>A</td>\n",
       "      <td>1A23_A</td>\n",
       "      <td>A</td>\n",
       "      <td>0.915</td>\n",
       "      <td>12178</td>\n",
       "      <td>6.28</td>\n",
       "      <td>12.57</td>\n",
       "      <td>['korpm', 'korpm_full']</td>\n",
       "      <td>['fireprot', 'q3421', 'korpm', 'korpm_full']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12CA_A</td>\n",
       "      <td>A</td>\n",
       "      <td>1A43_A</td>\n",
       "      <td>A</td>\n",
       "      <td>0.812</td>\n",
       "      <td>4097</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>['korpm', 'korpm_full']</td>\n",
       "      <td>['fireprot', 'q3421']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12CA_A</td>\n",
       "      <td>A</td>\n",
       "      <td>1A5E_A</td>\n",
       "      <td>A</td>\n",
       "      <td>0.985</td>\n",
       "      <td>11157</td>\n",
       "      <td>2.44</td>\n",
       "      <td>7.32</td>\n",
       "      <td>['korpm', 'korpm_full']</td>\n",
       "      <td>['fireprot', 'q3421', 'korpm', 'korpm_full']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12CA_A</td>\n",
       "      <td>A</td>\n",
       "      <td>1A7V_A</td>\n",
       "      <td>A</td>\n",
       "      <td>0.885</td>\n",
       "      <td>7372</td>\n",
       "      <td>1.77</td>\n",
       "      <td>8.85</td>\n",
       "      <td>['korpm', 'korpm_full']</td>\n",
       "      <td>['s669', 'korpm', 'korpm_full']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148597</th>\n",
       "      <td>9RNT_A</td>\n",
       "      <td>A</td>\n",
       "      <td>6BQG_A</td>\n",
       "      <td>A</td>\n",
       "      <td>0.632</td>\n",
       "      <td>6965</td>\n",
       "      <td>4.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>['korpm_full']</td>\n",
       "      <td>['fireprot']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148598</th>\n",
       "      <td>9RNT_A</td>\n",
       "      <td>A</td>\n",
       "      <td>6G4B_A</td>\n",
       "      <td>A</td>\n",
       "      <td>0.777</td>\n",
       "      <td>11756</td>\n",
       "      <td>2.78</td>\n",
       "      <td>4.17</td>\n",
       "      <td>['korpm_full']</td>\n",
       "      <td>['fireprot']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148599</th>\n",
       "      <td>9RNT_A</td>\n",
       "      <td>A</td>\n",
       "      <td>6JHM_A</td>\n",
       "      <td>A</td>\n",
       "      <td>0.898</td>\n",
       "      <td>12418</td>\n",
       "      <td>2.05</td>\n",
       "      <td>6.16</td>\n",
       "      <td>['korpm_full']</td>\n",
       "      <td>['fireprot']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148600</th>\n",
       "      <td>9RNT_A</td>\n",
       "      <td>A</td>\n",
       "      <td>6TQ3_A</td>\n",
       "      <td>A</td>\n",
       "      <td>0.709</td>\n",
       "      <td>6783</td>\n",
       "      <td>5.76</td>\n",
       "      <td>12.95</td>\n",
       "      <td>['korpm_full']</td>\n",
       "      <td>['fireprot']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148601</th>\n",
       "      <td>9RNT_A</td>\n",
       "      <td>A</td>\n",
       "      <td>8TIM_A</td>\n",
       "      <td>A</td>\n",
       "      <td>0.480</td>\n",
       "      <td>6552</td>\n",
       "      <td>4.08</td>\n",
       "      <td>10.20</td>\n",
       "      <td>['korpm_full']</td>\n",
       "      <td>['fireprot']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>148602 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        code_1 chain_1  code_2 chain_2  P-value  Afp-num  Identity (%)  \\\n",
       "0       12CA_A       A  1A0F_A       A    0.935    11638          3.64   \n",
       "1       12CA_A       A  1A23_A       A    0.915    12178          6.28   \n",
       "2       12CA_A       A  1A43_A       A    0.812     4097          0.00   \n",
       "3       12CA_A       A  1A5E_A       A    0.985    11157          2.44   \n",
       "4       12CA_A       A  1A7V_A       A    0.885     7372          1.77   \n",
       "...        ...     ...     ...     ...      ...      ...           ...   \n",
       "148597  9RNT_A       A  6BQG_A       A    0.632     6965          4.00   \n",
       "148598  9RNT_A       A  6G4B_A       A    0.777    11756          2.78   \n",
       "148599  9RNT_A       A  6JHM_A       A    0.898    12418          2.05   \n",
       "148600  9RNT_A       A  6TQ3_A       A    0.709     6783          5.76   \n",
       "148601  9RNT_A       A  8TIM_A       A    0.480     6552          4.08   \n",
       "\n",
       "        Similarity (%)               datasets_1  \\\n",
       "0                 9.09  ['korpm', 'korpm_full']   \n",
       "1                12.57  ['korpm', 'korpm_full']   \n",
       "2                 0.00  ['korpm', 'korpm_full']   \n",
       "3                 7.32  ['korpm', 'korpm_full']   \n",
       "4                 8.85  ['korpm', 'korpm_full']   \n",
       "...                ...                      ...   \n",
       "148597           12.00           ['korpm_full']   \n",
       "148598            4.17           ['korpm_full']   \n",
       "148599            6.16           ['korpm_full']   \n",
       "148600           12.95           ['korpm_full']   \n",
       "148601           10.20           ['korpm_full']   \n",
       "\n",
       "                                          datasets_2  \n",
       "0                                   ['s461', 's669']  \n",
       "1       ['fireprot', 'q3421', 'korpm', 'korpm_full']  \n",
       "2                              ['fireprot', 'q3421']  \n",
       "3       ['fireprot', 'q3421', 'korpm', 'korpm_full']  \n",
       "4                    ['s669', 'korpm', 'korpm_full']  \n",
       "...                                              ...  \n",
       "148597                                  ['fireprot']  \n",
       "148598                                  ['fireprot']  \n",
       "148599                                  ['fireprot']  \n",
       "148600                                  ['fireprot']  \n",
       "148601                                  ['fireprot']  \n",
       "\n",
       "[148602 rows x 10 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect information from running MMSeqs2 (sequence-only clustering) (expected at ../data/homology/sequence_homology.tsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2482202/2755249334.py:64: DtypeWarning: Columns (42) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_test = pd.read_csv(file2, index_col=0)\n",
      "/tmp/ipykernel_2482202/2755249334.py:64: DtypeWarning: Columns (42) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_test = pd.read_csv(file2, index_col=0)\n",
      "/tmp/ipykernel_2482202/2755249334.py:64: DtypeWarning: Columns (42) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_test = pd.read_csv(file2, index_col=0)\n",
      "/tmp/ipykernel_2482202/2755249334.py:41: DtypeWarning: Columns (42) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_train = pd.read_csv(file1, index_col=0)\n",
      "/tmp/ipykernel_2482202/2755249334.py:64: DtypeWarning: Columns (42) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_test = pd.read_csv(file2, index_col=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "korpm\n",
      "3122\n",
      "rosetta\n",
      "2082\n",
      "tsuboyama\n",
      "352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2482202/2755249334.py:64: DtypeWarning: Columns (42) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_test = pd.read_csv(file2, index_col=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fireprot\n",
      "3392\n",
      "s461\n",
      "89\n",
      "ssym\n",
      "1594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2482202/2755249334.py:64: DtypeWarning: Columns (42) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_test = pd.read_csv(file2, index_col=0)\n",
      "/tmp/ipykernel_2482202/2755249334.py:64: DtypeWarning: Columns (42) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_test = pd.read_csv(file2, index_col=0)\n"
     ]
    }
   ],
   "source": [
    "struct_ids = df[['code_1', 'code_2', 'P-value']]\n",
    "struct_ids.columns = ['source', 'target', 'P-value']\n",
    "struct_ids = struct_ids.loc[struct_ids['P-value']<0.01]\n",
    "struct_ids = struct_ids.loc[struct_ids['source']!=struct_ids['target']]\n",
    "\n",
    "# detect >=25% sequence identity based on MMSeqs2\n",
    "seq_ids = pd.read_csv('../data/homology/result.m8', sep='\\t', header=None)\n",
    "seq_ids = seq_ids.iloc[:, :3]\n",
    "seq_ids.columns = ['source', 'target', 'identity']\n",
    "# immediately only save rows with more than 25% identity\n",
    "seq_ids = seq_ids.loc[seq_ids['identity']>0.25]\n",
    "seq_ids = seq_ids.loc[seq_ids['source']!=seq_ids['target']]\n",
    "#all_codes = set(seq_ids['source']).union(set(seq_ids['target']))\n",
    "\n",
    "tmp = pd.read_csv(f'../data/inference/korpm_mapped_preds_clusters.csv', index_col=0)\n",
    "tmp = tmp[[c for c in tmp.columns if not 'overlap_seqs' in c]]\n",
    "tmp.to_csv(f'../data/inference/korpm_mapped_preds_clusters.csv')\n",
    "\n",
    "tmp = pd.read_csv(f'../data/inference/q3421_mapped_preds_clusters.csv', index_col=0)\n",
    "tmp = tmp[[c for c in tmp.columns if not 'overlaps' in c]]\n",
    "tmp.to_csv(f'../data/inference/q3421_mapped_preds_clusters.csv')\n",
    "\n",
    "#tmp = pd.read_csv('../data/fireprot_mapped_preds_clusters.csv', index_col=0)\n",
    "#tmp = tmp[[c for c in tmp.columns if not 'overlaps' in c]]\n",
    "#tmp.to_csv('../data/fireprot_mapped_preds_clusters.csv')\n",
    "\n",
    "id_table = pd.DataFrame()\n",
    "homo_struct_table = pd.DataFrame()\n",
    "homo_seq_table = pd.DataFrame()\n",
    "\n",
    "for file1 in ['../data/preprocessed/korpm_mapped.csv', \n",
    "              '../data/external_datasets/rosetta_mapped.csv', \n",
    "              '../data/preprocessed/tsuboyama_mapped.csv', \n",
    "              '../data/preprocessed/fireprot_mapped.csv', \n",
    "              '../data/preprocessed/q3421_mapped.csv',\n",
    "              '../data/preprocessed/s461_mapped.csv',\n",
    "              '../data/preprocessed/ssym_mapped.csv'\n",
    "              ]:\n",
    "    c = 'code' if ('ssym' not in file1) else 'wt_code'\n",
    "    # \"training\" data, e.g. sets that have been used to train models\n",
    "    df_train = pd.read_csv(file1, index_col=0)\n",
    "    if 'fireprot_mapped.csv' in file1:\n",
    "        df_train['position'] = df_train['position'].fillna(-100000).astype(int)\n",
    "        df_train['uid2'] = df_train['code'] + '_' + df_train['position'].astype(str) + df_train['mutation']\n",
    "        df_train = df_train.reset_index()\n",
    "        df_train = df_train.groupby('uid2').first()\n",
    "    # just extract the codes (structures) and dataset name\n",
    "    train_codes = set(df_train['code'])\n",
    "    name1 = file1.split('/')[-1].split('_')[0]\n",
    "    for file2 in ['../data/preprocessed/korpm_mapped.csv', \n",
    "                '../data/external_datasets/rosetta_mapped.csv', \n",
    "                '../data/preprocessed/tsuboyama_mapped.csv', \n",
    "                '../data/preprocessed/fireprot_mapped.csv', \n",
    "                '../data/preprocessed/q3421_mapped.csv',\n",
    "                '../data/preprocessed/s461_mapped.csv',\n",
    "                '../data/preprocessed/ssym_mapped.csv'\n",
    "                ]:  \n",
    "        #c = 'code' if ('ssym' not in file2) else 'wt_code'\n",
    "        name2 = file2.split('/')[-1].split('_')[0]\n",
    "\n",
    "        # overlap is a subset of train_codes\n",
    "        overlap_struct = set()\n",
    "        overlap_seq = set()\n",
    "        df_test = pd.read_csv(file2, index_col=0)\n",
    "        if 'fireprot_mapped.csv' in file2:\n",
    "            df_test['position'] = df_test['position'].fillna(-100000).astype(int)\n",
    "            df_test['uid2'] = df_test['code'] + '_' + df_test['position'].astype(str) + df_test['mutation']\n",
    "            df_test = df_test.reset_index()\n",
    "            df_test = df_test.groupby('uid2').first()\n",
    "        #print(len(df_train), len(df_test))\n",
    "\n",
    "        # this weird syntax just gets the intersection of the two datasets\n",
    "        id_table.at[name1, name2] = len(df_train.loc[list(set(df_train.index).intersection(set(df_test.index)))])\n",
    "        test_codes = set(df_test['code'])\n",
    "        #cc_test = df_test.loc[df_test['code'].isin(overlap_seq_codes)]\n",
    "\n",
    "        # determine which codes have over 25% similarity based on the \"data\"\n",
    "        for code in train_codes:\n",
    "            # trivial case\n",
    "            if code in test_codes:\n",
    "                overlap_struct.add(code)\n",
    "                overlap_seq.add(code)\n",
    "            else:\n",
    "                # get the relevant locations in the data (which pertain to the given train code)\n",
    "                overlap_struct_df = struct_ids.loc[(struct_ids['source'].str.contains(code))|(struct_ids['target'].str.contains(code))]\n",
    "                # check whether there are any cases where this code has homology to the test df\n",
    "                overlap_struct_df = overlap_struct_df.loc[(struct_ids['source'].str[:4].isin(test_codes))|(struct_ids['target'].str[:4].isin(test_codes))]                \n",
    "                if len(overlap_struct_df) > 0:\n",
    "                    overlap_struct.add(code)\n",
    "\n",
    "                # get the relevant locations in the data (which pertain to the given train code)\n",
    "                overlap_seq_df = seq_ids.loc[(seq_ids['source'].str.contains(code))|(seq_ids['target'].str.contains(code))]\n",
    "                # check whether there are any cases where this code has homology to the test df\n",
    "                overlap_seq_df = overlap_seq_df.loc[(seq_ids['source'].str[:4].isin(test_codes))|(seq_ids['target'].str[:4].isin(test_codes))]\n",
    "                if len(overlap_seq_df) > 0:\n",
    "                    overlap_seq.add(code)\n",
    "\n",
    "        homo_struct_table.at[name1, name2] = len(df_train.loc[df_train[c].isin(overlap_struct)])          \n",
    "        homo_seq_table.at[name1, name2] = len(df_train.loc[df_train[c].isin(overlap_seq)])\n",
    "        #print(name1, name2, overlap_seq)\n",
    "        #print(len(df_test.loc[df_test['code'].isin(overlap_seq)]))\n",
    "\n",
    "        if name1 != name2:\n",
    "            if 'q3421' in name1:\n",
    "                name2_ = name2\n",
    "                df_train[f'overlap_seqs_{name2_}'] = False\n",
    "                print(name2_)\n",
    "                print(len(df_train.loc[df_train['code'].isin(overlap_seq), f'overlap_seqs_{name2_}']))\n",
    "                df_train.loc[df_train['code'].isin(overlap_seq), f'overlap_seqs_{name2_}'] = True\n",
    "                tmp = pd.read_csv('../data/inference/q3421_mapped_preds_clusters.csv', index_col=0)\n",
    "                tmp = tmp.join(df_train[[f'overlap_seqs_{name2_}']])\n",
    "                tmp.to_csv('../data/inference/q3421_mapped_preds_clusters.csv')\n",
    "\n",
    "            if 'korpm' in name1:\n",
    "                name2_ = name2\n",
    "                df_train[f'overlap_seqs_{name2_}'] = False\n",
    "                df_train.loc[df_train['code'].isin(overlap_seq), f'overlap_seqs_{name2_}'] = True\n",
    "                tmp = pd.read_csv('../data/inference/korpm_mapped_preds_clusters.csv', index_col=0)\n",
    "                tmp = tmp.join(df_train[[f'overlap_seqs_{name2_}']])\n",
    "                tmp.to_csv('../data/inference/korpm_mapped_preds_clusters.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>korpm</th>\n",
       "      <th>rosetta</th>\n",
       "      <th>tsuboyama</th>\n",
       "      <th>fireprot</th>\n",
       "      <th>q3421</th>\n",
       "      <th>s461</th>\n",
       "      <th>ssym</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>korpm</th>\n",
       "      <td>2369.0</td>\n",
       "      <td>299.0</td>\n",
       "      <td>860.0</td>\n",
       "      <td>1394.0</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rosetta</th>\n",
       "      <td>299.0</td>\n",
       "      <td>1210.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>619.0</td>\n",
       "      <td>908.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>124.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tsuboyama</th>\n",
       "      <td>860.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>256219.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fireprot</th>\n",
       "      <td>1394.0</td>\n",
       "      <td>619.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>6372.0</td>\n",
       "      <td>2244.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>170.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q3421</th>\n",
       "      <td>1050.0</td>\n",
       "      <td>895.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>2244.0</td>\n",
       "      <td>3421.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>205.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s461</th>\n",
       "      <td>141.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>461.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ssym</th>\n",
       "      <td>0.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>684.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            korpm  rosetta  tsuboyama  fireprot   q3421   s461   ssym\n",
       "korpm      2369.0    299.0      860.0    1394.0  1050.0  141.0    0.0\n",
       "rosetta     299.0   1210.0       33.0     619.0   908.0    4.0  124.0\n",
       "tsuboyama   860.0     33.0   256219.0    1022.0   106.0  135.0    0.0\n",
       "fireprot   1394.0    619.0     1022.0    6372.0  2244.0   49.0  170.0\n",
       "q3421      1050.0    895.0      106.0    2244.0  3421.0   50.0  205.0\n",
       "s461        141.0      4.0      135.0      49.0    50.0  461.0    0.0\n",
       "ssym          0.0    124.0        0.0     170.0   205.0    0.0  684.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Reference</th>\n",
       "      <th>korpm</th>\n",
       "      <th>rosetta</th>\n",
       "      <th>tsuboyama</th>\n",
       "      <th>fireprot</th>\n",
       "      <th>q3421</th>\n",
       "      <th>s461</th>\n",
       "      <th>ssym</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overlapping Entries</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>korpm</th>\n",
       "      <td>2369.0</td>\n",
       "      <td>1802.0</td>\n",
       "      <td>1086.0</td>\n",
       "      <td>2309.0</td>\n",
       "      <td>2280.0</td>\n",
       "      <td>1409.0</td>\n",
       "      <td>669.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rosetta</th>\n",
       "      <td>1059.0</td>\n",
       "      <td>1210.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>1081.0</td>\n",
       "      <td>1081.0</td>\n",
       "      <td>355.0</td>\n",
       "      <td>746.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tsuboyama</th>\n",
       "      <td>13814.0</td>\n",
       "      <td>4899.0</td>\n",
       "      <td>256219.0</td>\n",
       "      <td>13814.0</td>\n",
       "      <td>13191.0</td>\n",
       "      <td>9827.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fireprot</th>\n",
       "      <td>5810.0</td>\n",
       "      <td>4338.0</td>\n",
       "      <td>1645.0</td>\n",
       "      <td>6372.0</td>\n",
       "      <td>5950.0</td>\n",
       "      <td>2554.0</td>\n",
       "      <td>2474.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q3421</th>\n",
       "      <td>3251.0</td>\n",
       "      <td>2507.0</td>\n",
       "      <td>522.0</td>\n",
       "      <td>3421.0</td>\n",
       "      <td>3421.0</td>\n",
       "      <td>1255.0</td>\n",
       "      <td>1766.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s461</th>\n",
       "      <td>446.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>319.0</td>\n",
       "      <td>377.0</td>\n",
       "      <td>370.0</td>\n",
       "      <td>461.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ssym</th>\n",
       "      <td>666.0</td>\n",
       "      <td>620.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>684.0</td>\n",
       "      <td>684.0</td>\n",
       "      <td>398.0</td>\n",
       "      <td>684.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Reference              korpm  rosetta  tsuboyama  fireprot    q3421    s461  \\\n",
       "Overlapping Entries                                                           \n",
       "korpm                 2369.0   1802.0     1086.0    2309.0   2280.0  1409.0   \n",
       "rosetta               1059.0   1210.0       98.0    1081.0   1081.0   355.0   \n",
       "tsuboyama            13814.0   4899.0   256219.0   13814.0  13191.0  9827.0   \n",
       "fireprot              5810.0   4338.0     1645.0    6372.0   5950.0  2554.0   \n",
       "q3421                 3251.0   2507.0      522.0    3421.0   3421.0  1255.0   \n",
       "s461                   446.0    154.0      319.0     377.0    370.0   461.0   \n",
       "ssym                   666.0    620.0        0.0     684.0    684.0   398.0   \n",
       "\n",
       "Reference              ssym  \n",
       "Overlapping Entries          \n",
       "korpm                 669.0  \n",
       "rosetta               746.0  \n",
       "tsuboyama               0.0  \n",
       "fireprot             2474.0  \n",
       "q3421                1766.0  \n",
       "s461                   12.0  \n",
       "ssym                  684.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "homo_struct_table.index.name = 'Overlapping Entries'\n",
    "homo_struct_table.columns.name = 'Reference'\n",
    "homo_struct_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Reference</th>\n",
       "      <th>korpm</th>\n",
       "      <th>rosetta</th>\n",
       "      <th>tsuboyama</th>\n",
       "      <th>fireprot</th>\n",
       "      <th>q3421</th>\n",
       "      <th>s461</th>\n",
       "      <th>ssym</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overlapping Entries</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>korpm</th>\n",
       "      <td>2369.0</td>\n",
       "      <td>1549.0</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>2259.0</td>\n",
       "      <td>2181.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>604.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rosetta</th>\n",
       "      <td>1057.0</td>\n",
       "      <td>1210.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>1081.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>746.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tsuboyama</th>\n",
       "      <td>13814.0</td>\n",
       "      <td>3532.0</td>\n",
       "      <td>256219.0</td>\n",
       "      <td>13043.0</td>\n",
       "      <td>10497.0</td>\n",
       "      <td>5023.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fireprot</th>\n",
       "      <td>5182.0</td>\n",
       "      <td>3438.0</td>\n",
       "      <td>1572.0</td>\n",
       "      <td>6372.0</td>\n",
       "      <td>5172.0</td>\n",
       "      <td>447.0</td>\n",
       "      <td>1816.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q3421</th>\n",
       "      <td>3122.0</td>\n",
       "      <td>2082.0</td>\n",
       "      <td>352.0</td>\n",
       "      <td>3392.0</td>\n",
       "      <td>3421.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>1594.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s461</th>\n",
       "      <td>376.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>239.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>461.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ssym</th>\n",
       "      <td>670.0</td>\n",
       "      <td>620.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>684.0</td>\n",
       "      <td>684.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>684.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Reference              korpm  rosetta  tsuboyama  fireprot    q3421    s461  \\\n",
       "Overlapping Entries                                                           \n",
       "korpm                 2369.0   1549.0     1013.0    2259.0   2181.0   203.0   \n",
       "rosetta               1057.0   1210.0       94.0    1081.0   1024.0    61.0   \n",
       "tsuboyama            13814.0   3532.0   256219.0   13043.0  10497.0  5023.0   \n",
       "fireprot              5182.0   3438.0     1572.0    6372.0   5172.0   447.0   \n",
       "q3421                 3122.0   2082.0      352.0    3392.0   3421.0    89.0   \n",
       "s461                   376.0     80.0      239.0     252.0    152.0   461.0   \n",
       "ssym                   670.0    620.0        0.0     684.0    684.0     8.0   \n",
       "\n",
       "Reference              ssym  \n",
       "Overlapping Entries          \n",
       "korpm                 604.0  \n",
       "rosetta               746.0  \n",
       "tsuboyama               0.0  \n",
       "fireprot             1816.0  \n",
       "q3421                1594.0  \n",
       "s461                    8.0  \n",
       "ssym                  684.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "homo_seq_table.index.name = 'Overlapping Entries'\n",
    "homo_seq_table.columns.name = 'Reference'\n",
    "homo_seq_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s461\n",
      "669 461\n",
      "ssym\n",
      "684 684\n",
      "Index(['esmif_monomer_dir', 'runtime_esmif_monomer_dir',\n",
      "       'pll_esmif_monomer_dir', 'Cartddg_dir', 'Evo_dir', 'KORPM_dir',\n",
      "       'ddG_dir', 'esm2_15B_half_dir', 'esm2_3B_dir', 'mif_dir',\n",
      "       ...\n",
      "       'INPS3D_dir', 'INPS3D_inv', 'INPS-Seq_dir', 'INPS-Seq_inv',\n",
      "       'ThermoNet_dir', 'ThermoNet_inv', 'Dynamut2_dir', 'Dynamut2_inv',\n",
      "       'cluster_dir', 'cluster_inv'],\n",
      "      dtype='object', length=190)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2482202/1536594660.py:87: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  db2.loc[:, ['uid']] = db2['wt_code'] + '_' + db2['position_orig'].astype(str) + db2['wild_type']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "korpm\n",
      "2369 2369\n",
      "q3421\n",
      "3421 3421\n",
      "fireprot\n"
     ]
    }
   ],
   "source": [
    "# open each of the main dataset inference files\n",
    "for file1 in ['../data/inference/s461_mapped_preds_clusters.csv',\n",
    "              '../data/inference/ssym_mapped_preds_clusters.csv',\n",
    "              '../data/inference/korpm_mapped_preds_clusters.csv', \n",
    "              '../data/inference/q3421_mapped_preds_clusters.csv',\n",
    "              '../data/inference/fireprot_mapped_preds_clusters.csv']:  \n",
    "\n",
    "    dataset = file1.split('/')[-1].split('_')[0]\n",
    "    dataset_ = dataset\n",
    "\n",
    "    print(dataset)\n",
    "    if dataset == 's461':\n",
    "    # since s461 is a subset of s669, can just use calcs for s669\n",
    "        dataset_ = 's669'\n",
    " \n",
    "    db = pd.read_csv(file1).set_index(['uid', 'uid2'])\n",
    "    \n",
    "    # load effective number of sequences from separate file (generated by MSA transformer)\n",
    "    neff = pd.read_csv(os.path.join('..', 'data', 'features', f'neff_{dataset_}.csv'), header=None, index_col=0)\n",
    "    neff.index.name = 'code'\n",
    "    neff.columns = ['neff', 'sequence_length']\n",
    "\n",
    "    # neff file was generated with different sized alignments, the largest in terms of Neff was used\n",
    "    neff = neff.groupby(level=0).max()\n",
    "\n",
    "    db_feats = pd.read_csv(os.path.join('..', 'data', 'features', f'{dataset_}_local_mapped_feats.csv'))\n",
    "    db_feats['uid'] = db_feats['code'] + '_' + db_feats['position_orig'].astype(str) + db_feats['mutation']\n",
    "    db_feats['uid2'] = db_feats['code'] + '_' + db_feats['position'].fillna(-1000000).astype(int).astype(str) + db_feats['mutation']\n",
    "\n",
    "    db_feats = db_feats.set_index(['uid', 'uid2'])\n",
    "    db_feats = db_feats[['on_interface', 'entropy', 'conservation', 'column_completeness', 'completeness_score', 'n_seqs', 'structure_length', 'SS', 'code',\n",
    "                         'features', 'hbonds', 'saltbrs', 'b_factor', 'kdh_wt', 'kdh_mut', 'vol_wt', 'vol_mut', 'chg_wt', 'chg_mut', 'rel_ASA']] #'residue_depth', 'wt_code',\n",
    "\n",
    "    db_feats['on_interface'] = db_feats['on_interface'].astype(int)\n",
    "    db_feats['features'] = db_feats['features'].fillna(\"\")\n",
    "    db_feats['delta_kdh'] = db_feats['kdh_mut'] - db_feats['kdh_wt']\n",
    "    db_feats['delta_vol'] = db_feats['vol_mut'] - db_feats['vol_wt']\n",
    "    db_feats['delta_chg'] = db_feats['chg_mut'] - db_feats['chg_wt']\n",
    "    db_feats['to_proline'] = (db_feats.reset_index('uid2').index.str[-1] == 'P').astype(int)\n",
    "    db_feats['to_glycine'] = (db_feats.reset_index('uid2').index.str[-1] == 'G').astype(int)\n",
    "    db_feats['from_proline'] = (db_feats.reset_index('uid2').index.str[6] == 'P').astype(int)\n",
    "    db_feats['from_glycine'] = (db_feats.reset_index('uid2').index.str[6] == 'G').astype(int)\n",
    "    db_feats['helix'] = db_feats['SS'] == 'H'\n",
    "    db_feats['bend'] = db_feats['SS'] == 'S'\n",
    "    db_feats['turn'] = db_feats['SS'] == 'T'\n",
    "    db_feats['coil'] = db_feats['SS'] == '-'\n",
    "    db_feats['strand'] = db_feats['SS'] == 'E'\n",
    "    db_feats['active_site'] = db_feats['features'].str.contains('ACT_SITE')\n",
    "\n",
    "    db_feats = db_feats.drop(['kdh_wt', 'kdh_mut', 'vol_wt', 'vol_mut', 'chg_wt', 'chg_mut', 'features', 'SS'], axis=1)\n",
    "    db_feats = db_feats.reset_index().merge(neff['neff'].dropna(), on='code', how='left').drop('code', axis=1).set_index(['uid', 'uid2'])\n",
    "    db_feats['neff'] = db_feats['neff'].fillna(0)\n",
    "    #unique_indices = db_feats.groupby('uid')['neff'].idxmax()#.astype(int)\n",
    "    #db_feats = db_feats.loc[unique_indices].set_index(['uid', 'uid2'])\n",
    "\n",
    "    for feature in ['on_interface', 'features', 'rel_ASA', 'delta_kdh', 'delta_vol', 'delta_chg', 'to_proline', 'to_glycine', 'from_proline', 'from_glycine', 'helix', 'bend', 'turn', 'coil', 'strand', 'active_site']:\n",
    "        db_feats = db_feats.rename({feature: feature + '_dir'}, axis=1)\n",
    "\n",
    "    len_db = len(db)\n",
    "\n",
    "    if dataset != 'fireprot':\n",
    "        print(len(db_feats), len_db)\n",
    "        #assert len(db_feats) == len_db\n",
    "        db_mod = db.join(db_feats, how='left')\n",
    "    else:\n",
    "        db_feats = db_feats.drop(['b_factor', 'conservation'], axis=1)\n",
    "        db_mod = db.join(db_feats.rename({'uid': 'uid_'}, axis=1).rename({'uid2': 'uid'}, axis=1).rename({'uid_': 'uid2'}, axis=1), how='left')\n",
    "\n",
    "    if dataset == 'ssym':\n",
    "        # apply the structural clusters assigned to wild-type structures to mutants\n",
    "        for code in db_mod['wt_code'].unique():\n",
    "            cluster = db_mod.loc[db_mod['code']==code, 'cluster'].head(1).item()\n",
    "            db_mod.loc[db_mod['wt_code']==code, 'cluster'] = cluster\n",
    "\n",
    "        # assign a new direction column to keep track of wild type vs mutant structures\n",
    "        db_mod['direction'] = 'dir'\n",
    "        db_mod.loc[db_mod['code']!=db_mod['wt_code'], 'direction'] = 'inv'\n",
    "\n",
    "        # match the naming convention for predictions made by other authors\n",
    "        for col in ['KORPM', 'Cartddg', 'FoldX', 'Evo', 'Dyna2', 'PopMs', 'DDGun', 'TNet', 'ACDCNN', 'ddG', 'cluster']:\n",
    "            db_mod = db_mod.rename({col: col + '_dir'}, axis=1)\n",
    "\n",
    "        # get two new dataframes which are just the forward and reverse mutations, and then hstack them\n",
    "        db1 = db_mod.loc[db_mod['code'].str[:4]==db_mod['wt_code']]\n",
    "        db1 = db1.drop(['code', 'wt_code'], axis=1)\n",
    "        db2 = db_mod.loc[db_mod['code'].str[:4]!=db_mod['wt_code']]\n",
    "        db2.loc[:, ['uid']] = db2['wt_code'] + '_' + db2['position_orig'].astype(str) + db2['wild_type']\n",
    "        db2 = db2.set_index('uid')\n",
    "        db2 = db2.drop(['code', 'wt_code'], axis=1)\n",
    "        db2.columns = [c.replace('_dir', '_inv') for c in db2.columns]\n",
    "        db2 = db2[[c for c in db2.columns if '_inv' in c]]\n",
    "        db_flat = db1.join(db2)\n",
    "\n",
    "        # sequence methods are necessarily antisymmetric. This fills in missing or erroneous values\n",
    "        for col in db_flat.columns:\n",
    "            if '_dir' in col:\n",
    "                if any([e in col for e in ['esm2', 'esm1v', 'msa', 'tranception', 'ankh']]) and not 'runtime' in col:\n",
    "                    db_flat[col.replace('_dir', '_inv')] = -db_flat[col]\n",
    "\n",
    "        #db_ddgs_2 = db_flat[['ddG_dir', 'ddG_inv']]\n",
    "\n",
    "        # merge with Ssym+\n",
    "        ssymp = pd.read_csv(os.path.join('..', 'data', 'external_datasets', 'Ssym+_experimental.csv'))\n",
    "        ssymp['uid'] = ssymp['Protein'].str[:4].apply(lambda x: x.upper())  + '_' + ssymp['Mut_pdb'].str[1:]\n",
    "        ssymp = ssymp.set_index('uid')\n",
    "\n",
    "        test = db_flat.reset_index().set_index('uid').join(ssymp, lsuffix='_plus').reset_index().set_index('uid')\n",
    "\n",
    "        float_columns = list(test.select_dtypes(include=['float']).columns)\n",
    "        float_columns.extend(['cluster_dir', 'cluster_inv'])\n",
    "        db_class = test[float_columns]\n",
    "        db_class.columns = ['plus_' + c[:-5] if 'plus' in c else c for c in db_class.columns]\n",
    "        db_class = db_class.drop([c+'_dir' for c in ['ACDCNN', 'ACDC-NN-2str', 'plus_FoldX', 'plus_DDGun', 'PopMs', 'TNet', 'Dyna2']], axis=1)\n",
    "        db_class = db_class.drop([c+'_inv' for c in ['ACDCNN', 'ACDC-NN-2str', 'plus_FoldX', 'plus_DDGun', 'PopMs', 'TNet', 'Dyna2']], axis=1)\n",
    "        print(db_class.columns)\n",
    "        db_stacked = analysis_utils.stack_frames(db_class)\n",
    "\n",
    "        cols = db_mod.columns\n",
    "        cols = [c.replace('_dir', '') for c in cols]\n",
    "        db_mod.columns = cols\n",
    "        \n",
    "        join_cols = [c for c in db_mod.columns if not c in db_stacked.columns]\n",
    "        join_cols.remove('direction')\n",
    "        db_mod = db_mod.reset_index(drop=True)\n",
    "        db_mod['uid'] = db_mod['wt_code'] + '_' + db_mod['position_orig'].astype(str) + db_mod['mutation']\n",
    "\n",
    "        db_stacked = db_stacked.reset_index('direction')\n",
    "        db_stacked = db_stacked.join(db_mod.set_index('uid')[join_cols])\n",
    "        \n",
    "        db_stacked = db_stacked.reset_index()\n",
    "        db_stacked['uid2'] = db_stacked['wt_code'] + '_' + db_stacked['position'].astype(str) + db_stacked['mutation']\n",
    "        db_stacked = db_stacked.set_index(['direction', 'uid', 'uid2'])\n",
    "\n",
    "        #out_loc_flat = f'../data/analysis/{dataset}_flat_analysis.csv'\n",
    "        #db_stacked.to_csv(out_loc_flat)\n",
    "        db_mod = db_stacked\n",
    "\n",
    "    elif dataset == 's461':\n",
    "        # create and use a third index for matching with the S461 subset\n",
    "        db_full = db_mod.copy(deep=True)\n",
    "        db_full['uid3'] = db['code'] + '_' + db['PDB_Mut'].str[1:]\n",
    "        db_full = db_full.reset_index().set_index('uid3')\n",
    "\n",
    "        # preprocess S461 to align with S669\n",
    "        s461 = pd.read_csv(os.path.join('..', 'data', 'external_datasets', 'S461.csv'))\n",
    "        s461['uid3'] = s461['PDB'] + '_' + s461['MUT_D'].str[2:]\n",
    "        s461 = s461.set_index('uid3')\n",
    "        s461['ddG_I'] = -s461['ddG_D']\n",
    "        s461.columns = [s+'_dir' for s in s461.columns]\n",
    "        s461 = s461.rename({'ddG_D_dir': 'ddG_dir', 'ddG_I_dir': 'ddG_inv'}, axis=1)\n",
    "\n",
    "        # merge S669 with S461 (keeping predictions from both for comparison purposes)\n",
    "        db_mod = s461.join(db_full.drop(['PDB_dir', 'MUT_D_dir', 'ddG_dir', 'KORPMD_dir', 'CartddgD_dir',\n",
    "            'FoldXD_dir', 'EvoD_dir', 'Dyna2D_dir', 'PopMsD_dir', 'DDGunD_dir',\n",
    "            'TNetD_dir', 'ACDCNND_dir', 'ddG_inv'], axis=1), how='left').reset_index(drop=True).set_index(['uid', 'uid2'])\n",
    "\n",
    "    if 'ddG' in db_mod.columns and not 'ddG_dir' in db_mod.columns:\n",
    "        db_mod['ddG_dir'] = db_mod['ddG']\n",
    "    elif 'ddG_dir' in db_mod.columns and not 'ddG' in db_mod.columns:\n",
    "        db_mod['ddG'] = db_mod['ddG_dir']\n",
    "        \n",
    "    out_loc = f'../data/analysis/{dataset}_analysis.csv'\n",
    "    db_mod.to_csv(out_loc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pslm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
